{"/devops-learn/docs/cloud/":{"data":{"":"云计算的主要分为三类：\n基础设施即服务（IaaS）位于云计算架构层次的最底端。主要提供计算资源，存储资源，网络资源。 平台即服务（PaaS），位于云计算架构中的中间层。主要为用户提供一个基于互联网应用开发环境，以支持应用从创建到运行整个周期所需要的各种软硬件资源和工具。PaaS 实际上是指将软件研发的平台作为一种服务提供给用户，比如数据库，文件系统和运行环境。常见的产品 Windows Azure，Google App Engine，Sina App Engine。 软件即服务（SaaS）位于云计算架构的顶端。主要讲软件服务通过网络提供给用户，用户只需要通过浏览器或者其他符合要求的设备接入使用即可。常见产品钉钉，飞书，腾讯会议等。 IaaS 和 PaaS 的区别：\nIaaS 提供的只是硬件层面，实现硬件的可扩展性和可隔离性。 PaaS 在同一基础设施上为用户提供其专属的应用运行平台，实现多应用的可扩展性和隔离运行。"},"title":"Cloud"},"/devops-learn/docs/cloud/ali/01_ecs/":{"data":{"":"ECS（Elastic Compute Service）是阿里云提供的 IaaS 级别的云服务器。开箱即用，支持弹性伸缩。\nECS 实例：相当于一台虚拟服务器，包含 vCPU、内存、网络、磁盘、操作系统等基础组件。 镜像：相当于装机盘，为 ECS 实例提供操作系统和预装软件。 块存储：分布式存储设备，用于数据的存储。 快照：某一时间点云盘的实时副本，常用于数据的备份/恢复，镜像制作等。 安全组：一种虚拟防火墙，实现网络访问控制。 网络：主要是专有网络 VPC，在逻辑上可彻底隔离的云上私有网络。"},"title":"ECS"},"/devops-learn/docs/cloud/aws/":{"data":{"":"","acl#ACL":"Network ACL 是子网的防火墙，默认拒绝所有流量。","aws-全球基础设施#AWS 全球基础设施":"AWS 在全球有 27 个区域，区域是分散在世界各地数据中心的物理位置。每个区域都有多个可用区（Availability Zone），每个可用区都是一个独立的、故障隔离的区域。可用区是区域中的一个或多个数据中心。\n例如区域：\nus-east-1 eu-west-1 ap-southeast-1 各个区域直接通过高速网络连接，延迟低。是 AWS 的骨干网。","cidr#CIDR":"每个 VPC 都需要配置一个 CIDR，例如 10.0.0.0/16。 每个子网都需要配置一个 CIDR，例如 10.0.0.0/24，10.0.1.0/24，10.0.2.0/24。 每个子网的 CIDR 必须在 VPC 的 CIDR 范围内。","security-group#Security Group":"Security Group 是 EC2 实例的防火墙，默认拒绝所有流量。","vpc#VPC":"VPC 是 Virtual Private Cloud 的缩写，虚拟私有云。是在 AWS 上的一个逻辑隔离的虚拟网络。\n在区域中可以创建多个 VPC，一个区域最多 5 个 VPC。每个 VPC 都是一个独立的网络环境，可以在 VPC 中创建子网、路由表、安全组等。\n每个子网选择一个可用区，一个可用区可以创建多个子网。\n然后就可以将 EC2 实例部署到不同的子网中。","vpc-路由器#VPC 路由器":"VPC 路由器负责互联子网并在网关、NAT 网关等组件之间路由流量。\n路由表是用来配置 VPC 路由器的。","为什么不建议使用-aws-默认-vpc#为什么不建议使用 AWS 默认 VPC？":"AWS 默认 VPC 是一个为了方便用户快速开始而设计的“入门级”网络环境。它牺牲了安全性、灵活性和最佳实践来换取便捷性。\n第一是安全风险，它的所有子网默认都是公网的，且容易导致不同项目间缺乏网络隔离。 第二是设计僵化，它的 CIDR 块不可更改，极易导致与其他网络连接时发生 IP 冲突，也无法实现公私子网分离的最佳架构。1 第三是可扩展性差，它在多账户策略中会成为噩梦，因为所有账户的默认 VPC 网段都重叠。 第四是违背 IaC 原则，对于像 Terraform 这样的工具，依赖一个隐式的默认资源会使代码缺乏可移植性和明确性。","创建-vpc#创建 VPC":"创建 VPC 会默认创建一个路由表，路由表中会有一个默认路由，指向 Internet 网关。 还会默认创建一个 Network ACL，Network ACL 是子网的防火墙，默认拒绝所有流量。 还会默认创建一个 Security Group，Security Group 是 EC2 实例的防火墙，默认拒绝所有流量。","可用区#可用区":"可用区可以创建子网，可以是公有子网，也可以是私有子网。每个子网始终都是在一个可用区内的。\n可用区一般是由多个数据中心组成的。冗余电源，网络等，保证高可用。","应该怎么做#应该怎么做？":"为每个工作负载创建自定义 VPC：根据应用的需求，精心设计 IP 地址空间（CIDR block），确保不会与任何需要连接的网络重叠（如公司局域网、其他 VPC）。\n设计分层子网：\n公有子网：路由指向 Internet Gateway，用于放置面向公众的负载均衡器、NAT 网关、Bastion Host（跳板机）。 私有子网：路由指向 NAT Gateway（用于出站互联网访问）或仅指向内部网关，用于放置应用程序服务器、工作队列、缓存服务。 隔离子网（或数据子网）：没有通往互联网的路由，用于放置数据库、数据存储等最敏感的后端服务。 配置安全组和网络 ACL：\n只开放必要的端口和协议。 为每个子网创建自定义的 Security Group，限制入站和出站流量。 配置 Network ACL 以控制子网内流量，例如拒绝来自外部的 ICMP 流量。 启用 VPC 流日志（可选）：\n用于监控和分析 VPC 流量，帮助检测异常活动。 监控和维护：\n定期审查和更新安全组和网络 ACL，确保只允许必要的流量。 监控 VPC 流日志，及时发现和响应安全事件。","网关#网关":"如果要访问外部网络，还需要通过网关。每个 VPC 只有一个网关。负责出口流量和接收进入 VPC 的流量（入口流量）。"},"title":"AWS"},"/devops-learn/docs/linux/01_view_text/":{"data":{"":"cat：显示文件的所有内容。 more：读取文件，但不需要读取整个文件到内存中，支持向下翻页。 less：more 的反义词，支持上下翻页。尽量使用 less 这种不需要读取全部文件的指令，因为在线上执行 cat 是一件非常危险的事情，这可能导致线上服务器资源不足。 head：查看文件开头。 head -5 \u003cfile\u003e：显示文件前 5 行的内容。 head -n 5 和 head -5 是一样的。 tail：查看文件结尾： tail -n 5 \u003cfile\u003e：显示文件尾部 5 行的内容。 -f：同步显示更新内容。 wc：统计文件内容。 wc -l \u003cfile\u003e：统计指定文件中的内容有多少行。 wc -w \u003cfile\u003e：统计指定文件中的单词数。 wc -m \u003cfile\u003e：统计指定文件中的字符数。 默认显示行数和文件，使用 cat a.txt | wc -l 可以只显示 a.txt 文件的行数。"},"title":"查看文件内容"},"/devops-learn/docs/linux/02_tar/":{"data":{"":"Linux 里面打包和压缩是分开的两个命令 tar 和 gzip/bzip2。","tar#tar":"tar -cf \u003c压缩文件\u003e \u003c多个目录或文件\u003e -c --create 打包 -f 指定归档文件。总是用 -f 参数指定文件名，并放在参数集的最后。 tar -xf \u003c压缩文件\u003e -x --extract 解压 tar -xf /tmp/backup.tar -C /root： 把 /tmp/backup.tar 文件还原到 /root 目录下。 -C 解压到指定目录 tar -cf - /etc： - 表示压缩到标准输出。直接输出到标准输出没什么用，需要配合 |： 远程备份：tar -cf - /data | ssh user@host \"cat \u003e backup.tar\"，无临时文件，高效流式传输 流式压缩：tar -cf - /data | gzip \u003e backup.tar.gz，灵活选择压缩工具和参数。 内容检查：tar -cf - /data | tar -t -f -，不解压到磁盘即可查看内容。 计算校验和：tar -cf - /data | md5sum，直接计算归档包的哈希值。 加密：tar -cf - /data | gpg -c \u003e backup.tar.gpg，边打包边加密，提升安全性 tar -c /etc 和 tar -cf - /etc 类似，不同的是没有使用 -f 指定归档文件。一般默认的行为也是输出到标准输出。但是有一些历史版本不是的。这条命令的行为是隐式且可能变化的。 其他常用参数：\n-t --list 列出归档文件中的内容列表。例如 tar -tf t.tar。 -z gzip 压缩，tar.gz 或者 tgz。需要解压缩就加上 -z 参数。例如 tar -czf /tmp/backup.tar.gz /etc。tgz 是 .tar.gz 的简写。 -j bzip2 压缩，后缀 tar.bz2 或者 tbz2。需要解压缩就加上 -j 参数。例如 tar -cjf /tmp/backup.tar.bz2 /etc。tbz2 是 .tar.bz2 的简写。 -v --verbose：显示指令执行过程。 --exclude\t排除不需要打包的文件或目录。 tar 命令默认会打包所有文件，包括隐藏文件（以点 . 开头的文件和目录）。 tar -czvf backup_with_star.tar.gz * 不会打包隐藏文件，因为 shell 会先将 * 扩展为所有非隐藏的文件名。 gzip、bzip2 压缩，gzip 压缩更快，bzip2 压缩比例更高。","应用场景#应用场景":"tar -cf - /etc：- 表示将 tar 压缩包写入到标准输出，而不是写入文件。\n# 将 /etc 目录打包并用 gzip 压缩，保存为当前目录下的 etc-backup.tar.gz tar -czvf etc-backup.tar.gz /etc/ # 使用更现代的 zstd 压缩，速度更快 tar -c --zstd -vf app-backup.tar.zst /var/www/myapp/ # 备份网站目录，但排除日志文件和缓存目录 tar -czvf site-backup.tar.gz \\ --exclude='*.log' \\ --exclude='./cache' \\ /var/www/html/ # 使用文件列表来排除 tar -czvf backup.tar.gz -X exclude-list.txt /data/ # exclude-list.txt 内容： # *.tmp # logs/ # temp/ # 不需要特殊参数，tar 默认会保留权限、所有权和时间戳。 # 但在解压时，如果用普通用户解压，所有权信息会丢失（除非是 root）。 # 备份根目录 / 时要小心使用 --exclude 排除虚拟文件系统。 sudo tar -czvf full-system-backup.tar.gz --exclude=/proc \\ --exclude=/sys --exclude=/dev --exclude=/tmp --exclude=/run \\ --exclude=/mnt --exclude=/media / # 列出 backup.tar.gz 里所有的文件 tar -tzvf backup.tar.gz # 查找压缩包里是否包含某个配置文件 tar -tzvf backup.tar.gz | grep nginx.conf # 将本地目录打包压缩后，直接通过 SSH 传输到远程服务器保存 tar -czv /data/ | ssh user@backup-server \"cat \u003e /backup/server-data-$(date +%F).tar.gz\" # 或者直接在远程服务器上解压 tar -czv /data/ | ssh user@backup-server \"tar -xz -C /remote/backup/dir/\" # 打包过去 7 天内修改过的 .log 文件 find /var/log -name \"*.log\" -mtime -7 -exec tar -rvf weekly-logs.tar {} \\; # 然后再压缩 gzip weekly-logs.tar tar -czv /data/ | ssh user@backup-server \"cat \u003e /backup/server-data-$(date +%F).tar.gz\" 使用 cat \u003e 的原因：\n\u003e 是 shell 的一个操作符，它的作用是将它左边命令的标准输出，重定向到右边的文件。不会主动去读取它自己的标准输入（stdin）。"},"title":"打包压缩"},"/devops-learn/docs/linux/03_text_operation/":{"data":{"":"文本搜索一般会使用正则表达式。","awk#awk":"awk 一般用于对文本内容进行统计，按需要的格式进行输出。一般是作为 sed 的一个补充。awk 可以看成是一种编程语言。\n特别擅长处理结构化文本数据（如日志、CSV、命令输出等）。\nawk 和 sed 的区别：\nawk 用于比较规范的文本处理，用于统计数量并输出指定字段。 sed 一般用于把不规范的文本处理为规范的文本。 awk 的流程控制：\n输入数据前例程 BEGIN{}，读入数据前执行，做一些预处理操作。 主输入循环 {}，处理读取的每一行。 所有文件读取完成例程 END{}，读取操作完成后执行，做一些数据汇总。 常用的写法是只写主输入循环。\n记录和字段：\n每一行叫做 awk 的记录。 使用空格、制表符分隔开的单词叫做字段。 可以指定分隔的字段。 字段的引用：\n$1 $2 … $n 表示每一个字段，$0 表示当前行，awk '{print $1, $2, $3} filename' $NF 是最后一个字段，和 NF 不一样。 -F 改变字段的分隔符，awk -F ',' '{print $1, $2, $3}' filename，分隔符可以使用正则表达式。 系统变量：\nNR 表示当前处理的是第几行。 NF 字段数量，所以最后一个字段内容可以用 $NF 取出，$(NF-1) 代表倒数第二个字段。 FS 字段分隔符，默认是空格和制表符。 RS 行分隔符，用于分割每一行，默认是换行符。 OFS 输出的字段分隔符，用于打印时分隔字段，默认为空格。 ORS 输出行分隔符，用于打印时分隔记录，默认为换行符。 FNR 行数。 常用参数：\n-F：指定输入字段分隔符。这是最常用的参数。 awk -F: '{print $1}' /etc/passwd // 使用冒号 : 作为分隔符。 awk -F'[ :]' '{print $2}' file // 使用空格或冒号作为分隔符（正则表达式）。 -v：定义变量，用于从 Shell 向 awk 脚本传递值。awk -v name=\"Alice\" '{print name, $1}' file.txt。 -f：从脚本文件中读取 awk 命令，用于复杂的脚本。awk -f script.awk data.txt。","grep#grep":"grep 用来查找文件里符合条件的字符串。 grep 会把符合条件的行显示出来。\n[root@pooky init.d]# grep password /root/anaconda-ks.cfg # Root password [root@pooky init.d]# grep -i password /root/anaconda-ks.cfg # -i 忽略大小写 # Root password [root@pooky ~]# grep pass.... /root/anaconda-ks.cfg # 可以使用元字符 . 匹配任意一个字符 auth --enableshadow --passalgo=sha512 # Root password [root@pooky ~]# grep pass....$ /root/anaconda-ks.cfg # $ 表示结尾 auth --enableshadow --passalgo=sha512 # Root password [root@pooky ~]# grep pass...d$ /root/anaconda-ks.cfg # Root password [root@pooky ~]# grep pass.*$ /root/anaconda-ks.cfg # .* 就表示任意个字符 auth --enableshadow --passalgo=sha512 # Root password user --groups=wheel --name=admin --passwd=$6$Lh0jvsS/YklFVYDM$WjPFI.WaMd3be/qiyFVUQkjEFN0PGQcnRTJFUDejJMUS24DA.M2rJ039hi/ubRiaNY4QNt661FARlxZqL.nCs0 --iscrypted --gecos=\"admin\" [root@pooky ~]# grep ^# /root/anaconda-ks.cfg # 以 # 为开头的行 #version=DEVEL # System authorization information # Use CDROM installation media # Use graphical install","sed#sed":"sed 命令一般用于对文本内容做替换：sed [-hnV][-e","sort#sort":"对文本行进行排序，一般都是作为数据管道（pipe）的关键一环，与 uniq, awk, head 等命令组合，用于日志分析、数据统计和报告生成。\n常用参数：\n-n：按数字大小进行排序，而不是字母顺序。 -r、--reverse：逆序排序（降序）。 -k：指定排序的键。 -t、--field-separator=SEP 指定字段分隔符，默认是空格。处理 CSV 文件或以特定字符（如 :, ,）分隔的日志。 -u、--unique：在排序的同时去除重复行。 -o、--output=FILE：将结果输出到指定文件，可以覆盖原文件。 -h: 人类可读数字排序，能正确比较 2K, 1M, 100G 的大小。 # 查看当前最消耗内存的10个进程 ps aux | sort -rnk 4 | head -10 # 按用户 ID（第三列）从小到大排序 /etc/passwd 文件。 sort -t ':' -nk 3 /etc/passwd 万能管道公式：\n获取数据 (awk/grep/sed) -\u003e 排序 (sort) -\u003e 去重统计 (uniq -c) -\u003e 再次排序 (sort -nr) -\u003e 取顶部结果 (head)","uniq#uniq":"uniq 是一个用于报告或忽略文件中的重复行的过滤器。它的一个关键前提是：输入必须是排序过的，因为 uniq 只会检测相邻的重复行。\n-c --count 在每行前加上该行重复出现的次数。最常用参数，用于统计重复项的频率。 -d --repeated 仅显示重复出现的行（每组重复行只显示一次）。快速找出有哪些内容是重复的。 -u --unique 仅显示不曾重复出现的行（独一无二的行）。找出只出现一次的条目，例如排查异常的单次访问。","元字符#元字符":"常用的元字符：\n. 匹配除了换行符外的任意一个字符 * 匹配任意个跟它前面的字符 [] 匹配方括号中的字符类中的任意一个，比如 [Hh]ello 就可以匹配 hello 和 Hello。 ^ 匹配开头 $ 匹配结尾 \\ 转义字符 扩展元字符：\n+ 匹配前面的正则表达式至少出现一次 ? 匹配前面的正则表达式出现一次或者零次 | 匹配前面或者后面的正则表达式","删除#删除":"sed /匹配模式/d 删除匹配到的行：\nsed '/^#/d' file.txt，删除所有以 # 开头的行。 sed 's/^/# /' file.txt，在每一行的行首添加 #，相当于注释掉所有行。","常用参数#常用参数":"-n：显示行号 -C：num --context：显示匹配行前后（Context） 各 num 行内容。最常用。 -A num --after-context：显示匹配行之后（After） 的 num 行内容。 -B num\t--before-context：显示匹配行之前（Before） 的 num 行内容。 -r --recursive：递归搜索目录下的所有文件。 -o：只输出匹配到的部分（字符串），而不是输出包含匹配模式的整行。 -E：扩展正则表达式 让 ()、{}、|、+ 等元字符不再需要反斜杠转义。 -i：忽略大小写。 -v：反向选择，即过滤掉匹配指定模式的行，只显示那些不匹配的行。","应用场景#应用场景":"# 在日志中查找所有异常，并显示行号和前后 5 行上下文 grep -n -C 5 -i \"exception\\|error\\|fail\" /var/log/app/app.log # 查找今天的错误 (结合日期过滤) grep \"$(date '+%Y-%m-%d')\" /var/log/app.log | grep -i error # 查找指定时间范围的日志 # -A 999999: 显示匹配行之后的 999999 行 # -B 999999: 显示匹配行之前的 999999 行 grep \"2024-05-24 10:15:\" app.log -A 999999 | grep \"2024-05-24 10:20:\" -B 999999 # 使用 sed（更可靠） sed -n '/2024-05-24 10:15:/,/2024-05-24 10:20:/p' app.log # 使用 awk # 假如日志格式是 YYYY-MM-DD HH:MM:SS [日志内容] # $1 是日期部分（如 2024-05-24），$2 是时间部分（如 10:15:23） # $1\" \"$2 的意思是字符串连接，重新组成完整的时间字符串，然后进行字符串比较。 awk '$1\" \"$2 \u003e= \"2024-05-24 10:15:00\" \u0026\u0026 $1\" \"$2 \u003c= \"2024-05-24 10:20:00\"' app.log # 统计404状态的请求 grep \" 404 \" /var/log/nginx/access.log | wc -l # 找出访问量最大的IP (结合awk和sort) # grep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" access.log | sort | uniq -c | sort -nr | head -10 # 通过一个唯一的TraceID来追踪一个请求在整个集群中的流转 grep \"abc123-trace-id\" /var/log/microservice/*.log+","应用场景-1#应用场景":"# 有一个用户列表 users.txt，想知道有哪些用户是重复的 sort users.txt | uniq -d # 找出只出现一次的异常条目 grep \"Failed password\" /var/log/secure | sort | uniq -u 日志格式为 [日期 时间] 错误信息。需要统计有哪些类型的错误信息，而不关心它们发生的具体时间。\n[2023-10-27 10:01:23] Connection timeout [2023-10-27 10:05:45] Permission denied [2023-10-27 10:07:12] Connection timeout [2023-10-27 10:08:33] Disk full # 先使用sed/awk处理掉`[`和`]` sed 's/\\[.*\\] //' error.log | sort | uniq -c","应用场景-2#应用场景":"# 将旧 IP 地址替换为新 IP 地址，并创建备份文件 sed -i.bak 's/192.168.1.100/192.168.1.200/g' /etc/nginx/conf.d/*.conf # 修改文件中的路径（注意：分隔符可以用其他字符，如 #，以避免和路径中的 / 冲突） # 旧路径 /old/path 全局替换为新路径 /new/path # `#` 作为分隔符，而不是常见的 `/` sed -i 's#/old/path#/new/path#g' config.ini # 删除配置文件中的所有空行和注释行（以 # 开头） sed -i '/^#/d; /^$/d' /etc/foo.conf # 或者写成多条 -e sed -i -e '/^#/d' -e '/^$/d' /etc/foo.conf # 只查看日志文件中特定时间范围内的行（例如 14:00 到 14:30） sed -n '/May 10 14:00:00/,/May 10 14:30:00/p' /var/log/syslog # 提取 Jenkins 构建日志中 Git 提交的哈希值（假设格式为 Commit: abc123def） cat build.log | sed -n 's/.*Commit: \\([a-f0-9]\\{7,40\\}\\).*/\\1/p' # 提取本机的 IP 地址（假设是 eth0 网卡） ip addr show eth0 | sed -n 's/.*inet \\(192\\.168[^/]*\\).*/\\1/p' # 在脚本中动态修改配置文件中的端口号 NEW_PORT=8080 sed -i \"s/^Port.*/Port $NEW_PORT/\" /etc/ssh/sshd_config # 直接删除文件 script.sh 中所有行尾的回车符（\\r） # \\r 代表回车符（Carriage Return），是 Windows 换行符的一部分 # sed 会读取数据，直到遇到换行符 \\n 为止，不是绝对的文件末尾 sed -i 's/\\r$//' script.sh # 这是一个非常常见的用法！ # 在每行的行首或行尾添加内容 sed -i 's/^/HEADER: /' logfile.txt # 行首添加 sed -i 's/$/\\\\n/' file.txt # 行尾添加换行符（实际是追加\\n字符） 使用扩展正则 -r：为了让命令更清晰易读，建议总是使用 sed -r，避免过多的反斜杠 \\。","应用场景-3#应用场景":"# 提取 ps 命令输出的进程 ID 和命令 (PID 和 CMD) ps aux | awk '{print $2, $11}' | head # 获取所有登录的用户名 who | awk '{print $1}' # 分析 /etc/passwd，提取用户名和使用的 shell awk -F: '{print $1, $7}' /etc/passwd # 分析 /etc/passwd，提取用户名和使用的 shell awk -F: '{print $1, $7}' /etc/passwd # 正则过滤 awk -F \"'\" '/^menu/{ print $1 }' /boot/grub2/grub.cfg menuentry menuentry menuentry # 条件过滤 # 显示磁盘使用率超过 80% 的分区 df -h | awk '$5+0 \u003e 80 {print $1, $5}' # 找出内存使用超过 100MB 的进程 ps aux | awk '$6 \u003e 100000 {print $11, $6/1024 \"MB\"}' # 打印第 5 到第 10 行 awk 'NR\u003e=5 \u0026\u0026 NR\u003c=10' /var/log/syslog # 计算文件总大小（第5列是大小） ls -l | awk '{sum += $5} END {print \"Total Size: \", sum, \"bytes\"}' # 统计日志中每种 HTTP 状态码的出现次数（假设第9列是状态码） awk '{status_count[$9]++} END {for(s in status_count) print s, status_count[s]}' access.log # 计算系统平均负载（最后15分钟是$3） uptime | awk '{print \"15-min load average: \", $NF}' # NF 是最后一个字段 # 格式化输出 /etc/passwd awk -F: 'BEGIN {printf \"%-15s %-10s\\n\", \"Username\", \"Shell\"} {printf \"%-15s %-10s\\n\", $1, $7}' /etc/passwd | head # 为输出添加表头 netstat -tnlp | awk 'BEGIN {print \"Proto Recv-Q Send-Q Local Address\"} NR\u003e2 {print $1, $2, $3, $4}' # 假设 Nginx 访问日志格式为 # 192.168.1.1 - - [10/May/2023:14:12:33 +0800] \"GET /index.html HTTP/1.1\" 200 1234 # 统计每个 IP 的访问次数 awk '{ip_count[$1]++} END {for(ip in ip_count) print ip, ip_count[ip]}' access.log | sort -nr -k2 # 统计最受欢迎的 URL（第7列） awk '{url_count[$7]++} END {for(url in url_count) print url_count[url], url}' access.log | sort -nr | head","打印#打印":"p 打印命令，打印匹配的行。通常与 -n 选项一起使用。\nsed -n '/error/p' /var/log/syslog，只打印包含 error 的行，相当于 grep \"error\"。","插入文本#插入文本":"i\\text：在指定行前插入文本。\nsed '3i\\# This is a new line' file.txt，在第 3 行之前插入一行注释 。","替换#替换":"sed 's/old/new/' filename，将文件中所有的 old 替换为 new。\nsed -e 's/old/new/' -e 's/old/new/' filename ...，可以执行多次替换脚本但是不能省略 -e。 sed -i 's/old/nnew/' 's/old/new/' filename ...，直接修改文件内容。 sed 's/foo/bar/g' file.txt 将全文所有的 foo 替换为 bar。 g：全局替换，不加 g 只替换每一行中第一个匹配到的 “foo”。 p：打印发生替换的那一行。与 -n 选项连用。 i 或 I：忽略大小写进行匹配。","替换整行#替换整行":"c\\text：替换整行文本。\nsed '/old_line/c\\This is the new line content' file.txt","行范围#行范围":"n：第 n 行。sed '5s/foo/bar/' 只替换第 5 行的 foo。 n,m：第 n 到 m 行。sed '10,20s/foo/bar/g'。 $：最后一行。sed '$s/foo/bar/'。 /regexp/：匹配正则表达式的行。sed '/start/,/end/d' 删除从包含 start 的行到包含 end 的行之间的所有内容。","表达式#表达式":"赋值操作符：\n=，var1 = \"name\"，var2 = $1 ++ -- += -= *= /+ %= ^= 算数操作符：\n+ - * / % ^ 系统变量：\nFS 字段分隔符，默认是空格和制表符。 RS 行分隔符，用于分割每一行，默认是换行符。 OFS 输出的字段分隔符，用于打印时分隔字段，默认为空格。 ORS 输出行分隔符，用于打印时分隔记录，默认为换行符。 NR 表示当前处理的是第几行。 FNR 行数。 NF 字段数量，所以最后一个字段内容可以用 $NF 取出，$(NF-1) 代表倒数第二个字段。 [root@SGDLITVM0905 ~]# head -5 /etc/passwd | awk 'BEGIN{FS=\":\"}{print $1}' # BEGIN{FS=\":\"} 表示在读入之前设置字段分隔符为 :，也可以写成 awk -F \":\" '{print $1}' root bin daemon adm lp [root@SGDLITVM0905 ~]# head -5 /etc/passwd | awk 'BEGIN{FS=\":\"}{print $1,$2}' root x # 可以看出输出的字段分隔符默认为空格 bin x daemon x adm x lp x [root@SGDLITVM0905 ~]# head -5 /etc/passwd | awk 'BEGIN{FS=\":\";OFS=\"-\"}{print $1,$2}' # 输出的字段分隔符设置为 - root-x bin-x daemon-x adm-x lp-x [root@SGDLITVM0905 ~]# head -5 /etc/passwd | awk 'BEGIN{RS=\":\"}{print $0}' # 已 : 为行分隔符，输出每一行 root x 0 0 root /root /bin/bash bin x 1 1 bin /bin /sbin/nologin daemon [root@SGDLITVM0905 ~]# head -5 /etc/passwd | awk '{print NR}' # 显示行号 1 2 3 4 5 [root@SGDLITVM0905 ~]# head -5 /etc/passwd | awk '{print NR, $0}' 1 root:x:0:0:root:/root:/bin/bash 2 bin:x:1:1:bin:/bin:/sbin/nologin 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin 4 adm:x:3:4:adm:/var/adm:/sbin/nologin 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin [root@SGDLITVM0905 ~]# awk '{print FNR, $0}' /etc/hosts /etc/hosts # FNR 会重排行号 1 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 2 #::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 3 4 16.187.191.150 SGDLITVM0905.hpeswlab.net SGDLITVM0905 1 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 2 #::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 3 4 16.187.191.150 SGDLITVM0905.hpeswlab.net SGDLITVM0905 You have new mail in /var/spool/mail/root [root@SGDLITVM0905 ~]# awk '{print NR, $0}' /etc/hosts /etc/hosts # FNR 不会重排行号 1 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 2 #::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 3 4 16.187.191.150 SGDLITVM0905.hpeswlab.net SGDLITVM0905 5 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 6 #::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 7 8 16.187.191.150 SGDLITVM0905.hpeswlab.net SGDLITVM0905 [root@SGDLITVM0905 ~]# head -5 /etc/passwd | awk 'BEGIN{FS=\":\"}{print NF}' # NF 输出字段数量 7 7 7 7 7 You have new mail in /var/spool/mail/root [root@SGDLITVM0905 ~]# head -5 /etc/passwd | awk 'BEGIN{FS=\":\"}{print $NF}' # $NF 就可以获取到最后一个字段的内容 /bin/bash /sbin/nologin /sbin/nologin /sbin/nologin /sbin/nologin 关系操作符：\n\u003c \u003e \u003c= \u003e= == != ~ !~ 布尔操作符：\n\u0026\u0026 || ! 条件语句：\nif (表达式) awk 语句1 [ else awk 语句2 ] 多个语句可以使用 {} 括起来。\n[root@SGDLITVM0905 ~]# cat score.txt user1 60 61 62 63 64 65 user2 70 71 72 73 74 75 user3 80 81 82 83 84 85 user4 90 91 92 93 94 95 [root@SGDLITVM0905 ~]# awk '{if($2\u003e=80) print $1}' score.txt user3 user4 [root@SGDLITVM0905 ~]# awk '{if($2\u003e=80) print $1; print $2}' score.txt # 这种写法会把所有的第二个字段输出 60 70 user3 80 user4 90 [root@SGDLITVM0905 ~]# awk '{if($2\u003e=80) {print $1; print $2} }' score.txt # 如果想一起输出要加上 {} ，多个语句一起执行 60 70 user3 80 user4 90 while 循环：\nwhile(表达式) awk 语句1 do 循环：\ndo { awk 语句1 }while(表达式) for 循环：\nfor(初始值;判断条件;累加) awk 语句1 可以使用 break 和 continue。\n[root@SGDLITVM0905 ~]# cat score.txt user1 60 61 62 63 64 65 user2 70 71 72 73 74 75 user3 80 81 82 83 84 85 user4 90 91 92 93 94 95 [root@SGDLITVM0905 ~]# head -1 score.txt user1 60 61 62 63 64 65 [root@SGDLITVM0905 ~]# head -1 score.txt | awk 'for(c=2;c\u003c=NF;c++) print c' 2 3 4 5 6 7 [root@SGDLITVM0905 ~]# head -1 score.txt | awk 'for(c=2;c\u003c=NF;c++) print $c' # 输出值 61 62 63 64 65 [root@SGDLITVM0905 ~]# head -1 score.txt | awk 'for(c=2;c\u003c=NF;c++) print $c' # 输出值 61 62 63 64 65 数组：\n数组[下标] = 值，初始化数组。下标可以是数字，也可以是字符串。 for (变量 in 数组)，数组[变量] 获取数组元素 delete 数组[下标] 删除数组元素 [root@SGDLITVM0905 ~]# cat score.txt user1 60 61 62 63 64 65 user2 70 71 72 73 74 75 user3 80 81 82 83 84 85 user4 90 91 92 93 94 95 [root@SGDLITVM0905 ~]# awk '{ sum=0; for(column=2;column\u003c=NF;column++) sum+=$column; print sum }' score.txt # 计算每个人的总分 375 435 495 555 [root@SGDLITVM0905 ~]# [root@SGDLITVM0905 ~]# awk '{ sum=0; for(column=2;column\u003c=NF;column++) sum+=$column; avg[$1]=sum/(NF-1); }END{ for( user in avg) print user, avg[user]}' score.txt # 计算每个人的平均分 并在 END 例程中格式化输出 user1 62.5 user2 72.5 user3 82.5 user4 92.5 awk 脚本可以保存到文件：\n[root@SGDLITVM0905 ~]# awk -f avg.awk score.txt user1 62.5 user2 72.5 user3 82.5 user4 92.5 -f 加载 awk 文件。 avg.awk 文件的内容：{ sum=0; for(column=2;column\u003c=NF;column++) sum+=$column; avg[$1]=sum/(NF-1); }END{ for( user in avg) print user, avg[user]}。 命令行参数数组：\nARGC 命令行参数数组的长度。 ARGV 命令行参数数组。 [root@SGDLITVM0905 ~]# cat arg.awk BEGIN{ for(x=0;x","追加#追加":"a\\text：在指定行后追加文本。\nsed '/server_name www.example.com;/a\\ return 301 https://$host$request_uri;' nginx.conf，在 server_name 行后追加一条 301 重定向规则。"},"title":"操作文本"},"/devops-learn/docs/linux/04_find/":{"data":{"":"","find#find":"find 命令用来在指定目录下查找文件。格式：find \u003c文件路径\u003e \u003c查找条件\u003e [补充条件]。\n[root@pooky ~]# find /etc -name pass* # 查找 /etc 目录下 pass 前缀的文件 /etc/pam.d/passwd /etc/pam.d/password-auth-ac /etc/pam.d/password-auth /etc/openldap/certs/password /etc/passwd /etc/selinux/targeted/active/modules/100/passenger /etc/passwd- [root@pooky ~]# find /etc -regex .*wd$ # 使用正则 -regex /etc/security/opasswd /etc/pam.d/passwd /etc/passwd [root@pooky ~]# find /etc -type f -regex .*wd$ /etc/security/opasswd /etc/pam.d/passwd /etc/passwd 常用参数：\n-name：按文件名查找（区分大小写）。 -iname：按文件名查找（不区分大小写）。 -type：按文件类型查找。find /var -type d -name \"log\" 在 /var 下查找所有名为 log 的目录。 f：普通文件 (file)。 d：目录 (directory)。 l：符号链接 (link)。 -mtime：按文件内容修改时间查找（天为单位），find /var/log -name \"*.log\" -mtime -1，查找 /var/log 下昨天到现在修改过的日志文件。 -mtime +n：n 天之前被修改过的文件。 -mtime -n：n 天之内被修改过的文件。 -mtime n：正好 n 天前被修改过的文件。 -mmin：按文件内容修改时间查找（分钟为单位），find /tmp -cmin -10 查找 /tmp 下 10 分钟之内内容被修改过的文件。 -atime/-amin：按文件访问时间查找（天/分钟）。 -ctime/-cmin：按文件状态改变时间查找（如权限、属主）。 -size：按文件大小查找，find / -type f -size +100M 在整个系统查找大于 100MB 的文件（常用于定位磁盘空间杀手）。 -size +n：大于 n 个指定单位的文件 find /var/log -name \"*.log\" -size +1G 查找超过 1G 的巨大日志文件。 -size -n：小于 n 个指定单位的文件。 单位：c（字节），k（KB），M（MB），G（GB）。 -perm：按文件权限查找。 -perm 644：查找权限正好是 644 的文件。 -perm -644：查找权限包含 644 的文件（如 755, 644 都匹配，因为都包含了 rw-r--r--）。 -user：按文件属主查找，find /home -user pooky 查找属于用户 pooky 的所有文件。 -group：按文件属组查找。","whereis#whereis":"在一个标准的 Linux 系统目录列表（如 /bin, /usr/bin, /usr/local/bin, /usr/share/man 等）中搜索某个命令的二进制文件（可执行文件）、源代码文件和 man 帮助手册文件。\n-b 只搜索二进制（可执行）文件。\twhereis -b nginx。 -m 只搜索手册页文件。whereis -m ls。 -s 只搜索源代码文件。whereis -s bash。","which#which":"在用户的 PATH 环境变量所指定的目录列表中，搜索某个可执行命令的完整路径。\nwhich 只找能直接运行的命令。\n-a 显示所有匹配的可执行文件路径，而不仅仅是第一个。 用 which 检查一下，如果没输出，说明该命令确实不在 PATH 中。","应用场景#应用场景":"# 清理 /tmp 下超过 7 天未访问的临时文件 find /tmp -type f -atime +7 -delete # 清理 /var/log 下超过 30 天的日志文件（.log.gz 等压缩过的日志） find /var/log -name \"*.log*\" -mtime +30 -delete # 查找当前目录下大于 500MB 的文件，并按大小排序 find . -type f -size +500M -exec ls -lh {} \\; | sort -k 5 -hr # 查找所有 .conf 配置文件，并用 tar 打包备份 find /etc -name \"*.conf\" -exec tar -rvf backup.tar {} \\; # 将某个用户（如nginx）创建的所有文件属主改为 www-data find /srv/www -user nginx -exec chown www-data:www-data {} \\; # 批量修改目录权限为 755，文件权限为 644 find /path/to/dir -type d -exec chmod 755 {} \\; find /path/to/dir -type f -exec chmod 644 {} \\; # 统计当前目录下 JavaScript 文件的数量 find . -name \"*.js\" | wc -l # 忽略错误输出：在搜索根目录 / 时，会遇到大量权限拒绝的错误，干扰查看结果。可以将错误重定向到黑洞。 find / -name \"something\" 2\u003e/dev/null 先确认，再操作：在使用 -exec、-delete 等具有破坏性的参数前，先用 -print 或 -ls 模拟运行一次，确认找到的文件是你要操作的目标。","执行操作#执行操作":"-exec：对匹配的文件执行指定的命令。命令以 ; 结束，{} 是查找结果的占位符。; 需要转义。 -ok：与 -exec 类似，但在执行命令前会交互式地询问用户确认，更安全。 -delete：直接删除匹配的文件。 # 查找并删除 /tmp 下所有 .tmp 文件 find /tmp -name \"*.tmp\" -exec rm -f {} \\;","逻辑操作符#逻辑操作符":"-a 或 -and：与（默认操作符，可省略）。 -o 或 -or：或。 ! 或 -not：非。 ()：组合条件，提高优先级。括号需要被转义或引用，如 \\( ... \\) 或 '( ... )'。 # 查找所有 .txt 或 .md 文件 find . \\( -name \"*.txt\" -o -name \"*.md\" \\) # 查找所有不属于 root 用户的文件 find . ! -user root"},"title":"查找文件"},"/devops-learn/docs/linux/05_cpu/":{"data":{"":"","ps#ps":"查看进程状态快照。\nps aux：(最常用) 显示所有用户的所有进程的详细信息。相比较 ps -ef 多了两列 %CPU 和 %MEM，少了一列 PPID。 ps -ef：显示所有进程的完整格式信息。 ps -eF：显示所有进程的更详细的完整格式信息。 ps -eo：自定义输出列。 ps -eLf：显示线程。 # 查找 nginx 或 java 进程 ps aux | grep nginx ps aux | grep java # 按 CPU 使用率降序排列 # sort 参数可能有些系统不支持，sort 命令功能更丰富 ps aux --sort=-%cpu | head -10 # 按内存使用率降序排列 ps aux --sort=-%mem | head -10 # 查看进程的父进程 ID （PPID） ps -eo pid,ppid,cmd | grep \u003c进程名\u003e # 检查僵尸进程 ps aux | awk '$8==\"Z\" {print $0}'","pstree#pstree":"以树状结构显示进程之间的父子关系。\n-p，--pid (最常用) 显示进程ID（PID）。 -a，--arguments 显示命令行参数。 -u，--user 显示用户信息。 -H，--highlight 高亮显示指定进程及其祖先。 使用场景：\n直观查看系统的进程层次结构。 排查“杀不掉的进程” ： 如果一个进程反复被拉起，用 pstree 可以清晰地看到它的父进程是谁，从而找到根源并处理父进程。 分析由守护进程（如 systemd, supervisord）管理的服务查看服务的所有子进程是否正常启动。","top#top":"top 显示进程和系统信息。其实和 ps 差不多，只不过显示的是实时数据。它是交互式的。\n常用交互指令:\nP (大写) 按 CPU 使用率排序； M (大写) 按 内存使用率（RES） 排序； N (大写) 按 PID 排序； T (大写) 按 CPU 时间（TIME+） 排序； k 终止一个进程（会提示输入PID）； r renice（修改进程优先级）； 1 展开显示所有CPU核心的详细使用情况。 top 命令进程的几种状态：\nR 运行（正在运行或等待运行）； S 中断（睡眠）； D 不可中断（等待 IO）； Z 僵尸（已终止，但父进程未回收）； T 停止（已停止）； N 不可见（没有显示）。","三者的协同工作流#三者的协同工作流":"top：发现问题。发现系统负载很高，CPU %wa（等待 IO）指标飙升。 在 top 中按 M：初步定位。发现没有进程占用特别高的内存或CPU。 ps aux：深入分析。结合 grep 和状态过滤，寻找处于 D（不可中断睡眠）状态的进程，这通常是导致高 IO 等待的根源： ps aux | awk '$8==\"D\" {print $0}'， 查找 D 状态的进程。 pstree -p：追溯根源。如果找到问题进程，用 pstree 查看是谁启动了它，判断影响范围，决定是终止子进程还是父进程。 kill -9 ：强制终止进程。如果终止后问题没有解决，可能需要重启系统。 top：再次检查。确认问题是否解决。","进程管理#进程管理":"ps：拍一张静态照片，用于详细分析、查找和记录。 top：打开实时直播，用于动态监控和即时操作。 pstree：画一张家谱/关系图，用于理解进程间的依赖和层次关系。"},"title":"CPU"},"/devops-learn/docs/linux/06_mem/":{"data":{"":"","free#free":"查看系统的物理内存和交换空间（swap）的使用情况：\n-h (最常用)，以人类易读的单位（G, M, K）显示数据。 -s \u003c间隔\u003e，以指定的间隔（秒）持续刷新显示内存状态。用于实时监控。 -c \u003c次数\u003e，与 -s 连用，指定刷新显示的次数后退出。 -t，在输出结果的最后增加一行总计（Total），汇总物理内存和 Swap 的总和。","内存管理#内存管理":""},"title":"内存"},"/devops-learn/docs/linux/07_disk/":{"data":{"":"","df#df":"用于查看已挂载的文件系统的整体磁盘空间使用情况。操作对象是文件系统。\n-h：(最常用)\t以人类易读格式显示（G, M, K）。 -T：显示文件系统类型（如 ext4, xfs, tmpfs）。 -i：显示 inode 使用情况 而非块使用情况。 -t \u003c类型\u003e：只显示指定类型的文件系统，例如 df -t xfs，只显示 XFS 类型。 -x \u003c类型\u003e：排除指定类型的文件系统。 # 排查 \"No space left on device\" 错误 # 情况1：磁盘空间满了 df -h # 情况2：磁盘空间没满，但 inode 用完了（常见于有大量小文件的系统） df -hi # 只查看本地磁盘，排除临时文件系统（如 tmpfs） df -hT -x tmpfs -x devtmpfs","du#du":"du (disk usage) 用于查看具体文件或目录占用了多少磁盘空间。操作对象是文件/目录。\n显示的实际占用的空间，默认单位是 KB。ls -l 查看的文件大小包含了部分空洞的空间。\n-h：(最常用)\t以人类易读格式显示。 -s：只显示总用量摘要，不显示子目录详情。 -c：除了显示大小，最后再显示一个总计。 --max-depth=N：显示到第 N 级子目录的深度。 # 定位磁盘空间被谁占用了（df 发现满之后的下一步） # 1. 先查看根目录下哪个一级目录最大 du -sh --max-depth=1 / # 2. 发现是 /var 很大，再深入查看 /var 下哪个子目录最大 du -sh --max-depth=1 /var # 3. 发现是 /var/log 很大，继续深入... du -sh --max-depth=1 /var/log # 查看某个特定目录的总大小 du -sh /home/wwwroot # 查找并清理大文件或旧文件 # 结合 sort 和 head 命令找出 /var/log 下最大的10个文件或目录 du -h /var/log | sort -rh | head -10","fdisk#fdisk":"查看磁盘，磁盘分区。（parted -l 和 fdisk -l 类似）。 操作对象是磁盘本身（如 /dev/sda），而不是分区（如 /dev/sda1）。\n-l (最常用)\t列出指定磁盘的分区表，例如 fdisk -l /dev/sda。不指定磁盘设备则列出所有磁盘，例如 fdisk -l。","交互模式#交互模式":"# 为新添加的硬盘创建分区 fdisk /dev/sdb # 进入交互模式 # 进入交互模式后，常用流程： # 1. 输入 `n` 创建新分区 # 2. 选择主分区/扩展分区 (p/e) # 3. 设置分区号 (1-4) # 4. 设置起始扇区（直接回车用默认值） # 5. 设置结束扇区或大小（如 +10G） # 6. 输入 `p` 预览分区表 # 7. 确认无误后输入 `w` 保存并退出 # 修改分区类型 fdisk /dev/sdb # 输入 `t`，然后选择分区号，最后输入分区类型的十六进制代码（如 LVM 是 `8e`，Swap 是 `82`）","磁盘管理#磁盘管理":"fdisk：管“盘”的（物理/虚拟磁盘）； df：管“分区”的（已挂载的文件系统）； du：管“文件”的（目录和文件的大小）。"},"title":"磁盘"},"/devops-learn/docs/linux/08_net/":{"data":{"":"net-tools 是 CentOS 7 之前的版本使用的网络管理工具，而 iproute2 是 CentOS 7 之后主推的网络管理工具。\nnet-tools 包括：\nifconfig 网卡配置； route 网关配置； netstat 查看网络状态。 iproute2 包括：\nip：包含里 ifconfig 和 route 的功能； ss：类似 netstat ，更快更强。","ip-addr-命令#ip addr 命令":"ip addr 命令用于查看和管理网络接口的 IP 地址。","ip-route-命令#ip route 命令":"ip route 命令它不仅仅是用来“查看路由表”，更是操作 Linux 内核路由表的核心工具。","ip-route-命令的角色#ip route 命令的角色":"ip route 是 iproute2 软件套件的一部分，用于查看和管理内核中的路由表（Routing Table）。它的工作原理可以理解为用户空间与内核空间之间的一个桥梁：\n用户输入命令：例如 ip route add 192.168.2.0/24 via 192.168.1.1。 内核系统调用：通过 Netlink 套接字（一种专门用于内核与用户进程通信的机制）将“添加路由”的请求发送给 Linux 内核。 内核处理请求：内核网络栈接收到请求后，会根据请求参数（如目标网络、下一跳地址等）进行解析和处理。 内核修改路由表：内核网络栈接收到请求后，在其内部的路由表中创建、删除或修改相应的路由条目。 生效：此后，所有进出主机的数据包转发决策都将依据新的路由表进行。","ip-命令#ip 命令":"","mtr#mtr":"运行 mtr 可以查看更详细的网络状态：\n类别 参数 作用 示例 协议/端口 -T TCP SYN 探测 mtr -T -P 443 1.1.1.1 -u UDP 探测 mtr -u -P 53 8.8.8.8 -P 指定目标端口 mtr -T -P 443 1.1.1.1 输出格式 -n 不解析主机名（纯 IP） mtr -n 8.8.8.8 -r 报告模式（一次性统计） mtr -r 8.8.8.8 -c 发送 N 次探测后结束 mtr -r -c 100 8.8.8.8 时间控制 -i 每次探测间隔（秒） mtr -i 0.5 8.8.8.8 -p 同 -i（兼容写法） mtr -p 0.5 8.8.8.8 TTL/跳数 -m 最大跳数（默认 30） mtr -m 50 8.8.8.8 调试/帮助 -4 / -6 强制 IPv4 / IPv6 mtr -4 8.8.8.8 -h 查看全部选项 mtr -h mtr -n baidu.com 输出示例：\nMy traceroute [v0.95] DESKTOP-DMAGDPE (172.18.149.141) -\u003e bdidu.com (76.223.54.146) 2025-08-27T15:34:02+0800 Keys: Help Display mode Restart statistics Order of fields quit Packets Pings Host Loss% Snt Last Avg Best Wrst StDev 1. 172.18.144.1 0.0% 9 0.6 0.7 0.2 1.5 0.4 2. 192.168.31.1 0.0% 9 2.1 2.5 1.5 4.2 1.0 3. 192.168.1.1 0.0% 9 4.0 3.3 2.1 4.0 0.6 4. 100.84.128.1 0.0% 9 6.4 8.7 5.4 19.5 4.2 5. (waiting for reply) 6. (waiting for reply) 7. (waiting for reply) 8. (waiting for reply) 9. 219.158.3.214 50.0% 9 30.4 31.1 30.2 32.7 1.2 10. 219.158.3.102 33.3% 9 62.7 61.7 60.3 62.7 0.9 11. 219.158.34.230 0.0% 9 86.4 88.9 85.4 107.6 7.6 12. (waiting for reply) 13. (waiting for reply) 14. (waiting for reply) 15. 52.93.8.41 0.0% 8 95.2 94.8 92.7 99.4 2.2 16. 52.93.8.18 0.0% 8 86.7 87.8 85.8 94.2 2.9 17. 76.223.54.146 0.0% 8 85.9 86.3 84.9 88.5 1.1 mtr 输出列解读：\nLoss%：丢包率。这是最重要的指标，某一跳的丢包率突然升高，通常意味着该节点或链路有问题。 Host：主机名或 IP 地址。 Snt：发送的探测包数量。 Last：最近一次的延迟（毫秒）。 Avg：平均延迟（毫秒）。 Best：最佳延迟（毫秒）。 Wrst：最差延迟（毫秒）。 StDev：延迟抖动（标准方差）。这个值越大，说明网络越不稳定。","ss-命令#ss 命令":"属于 iproute2 工具包，类似 netstat，参数类似，显示格式不同。\n两者的区别：\n性能：ss 直接从内核空间获取信息，速度极快。而 netstat 会遍历 /proc/net 下的文件，在连接数非常多时（如数万）速度很慢。 信息更丰富：ss 可以显示更多的 TCP 内部状态信息（如拥塞控制、内存使用等）。 格式为：ss [选项] [过滤器]\n-t：显示 TCP sockets。ss -t。 -u：显示 UDP sockets。ss -u。 -l：显示正在监听（Listen）的 sockets。ss -tl。 -a：显示所有 sockets（包括监听和非监听）。ss -ta。 -n：不解析服务名称（显示端口号而不是像“http”这样的名字）。强烈推荐始终使用，速度更快且信息更准确。ss -tn。 -p：显示使用 socket 的进程信息（需要 sudo）。sudo ss -tp。 -4：仅显示 IPv4 sockets。ss -t4。 -6：仅显示 IPv6 sockets。ss -t6。 过滤选项:\nsport = :端口号：过滤源端口。ss sport = :80。 dport = :端口号：过滤目标端口。ss dport = :443。 src IP地址：过滤源 IP 地址。ss src 192.168.1.100。 dst IP地址：过滤目标 IP 地址。ss dst 8.8.8.8。 state：过滤连接状态。ss state established。 输出选项:\n-e：显示详细的 socket 信息（如 UID、内存等）。ss -te。 -o：显示 TCP 计时器信息（如 TCP 重传超时）。ss -to。 -i：显示 TCP 内部信息（拥塞控制、流量控制）。ss -ti。 -m：显示 socket 的内存使用情况。ss -tm。 -s：打印摘要统计信息（非常有用）。ss -s。","tcpdump#tcpdump":"tcpdump -i any 07:02:12.195611 IP test.ya.local.59915 \u003e c2.shared.ssh: Flags [.], ack 1520940, win 2037, options [nop,nop,TS val 1193378555 ecr 428247729], length 0 07:02:12.195629 IP c2.shared.ssh \u003e test.ya.local.59915: Flags [P.], seq 1520940:1521152, ack 1009, win 315, options [nop,nop,TS val 428247729 ecr 1193378555], length 212 07:02:12.195677 IP test.ya.local.59915 \u003e c2.shared.ssh: Flags [.], ack 1521152, win 2044, options [nop,nop,TS val 1193378555 ecr 428247729], length 0 07:02:12.195730 IP c2.shared.ssh \u003e test.ya.local.59915: Flags [P.], seq 1521152:1521508, ack 1009, win 315, options [nop,nop,TS val 428247730 ecr 1193378555], length 356 -i：指定网卡，any 表示任意网卡。如果只需要查看某个网卡的数据包，例如 ehh0，使用 tcpdump -i eth0。","traceroute#traceroute":"traceroute -w 1 www.baidu.com：\n-w 等待响应的超时时间，单位为秒，-w 1 表示某个 IP 超时的最大等待时间为 1 秒。 -n 显示 IP 地址。 -m 设置最大跳数，默认 64。 -q 每个网关发送数据包个数，默认 3。 -p 指定使用的目标端口。 -I，--icmp 使用 ICMP ECHO 作为探测包。 -M，--type=Method 指定使用的探测方法（icmp 或者 udp），默认 udp。 [root@shcCDFrh75vm8 ~]# traceroute -w 1 www.baidu.com traceroute to www.baidu.com (104.193.88.77), 30 hops max, 60 byte packets 1 gateway (16.155.192.1) 0.525 ms 0.635 ms 0.800 ms 2 10.132.24.193 (10.132.24.193) 0.600 ms 0.930 ms 1.137 ms 3 192.168.201.122 (192.168.201.122) 0.826 ms 0.746 ms 0.674 ms 4 192.168.200.45 (192.168.200.45) 2.045 ms 1.978 ms 1.962 ms 5 192.168.203.249 (192.168.203.249) 29.375 ms 29.351 ms 29.275 ms 6 192.168.203.250 (192.168.203.250) 3.892 ms 2.980 ms 2.907 ms 7 192.168.200.185 (192.168.200.185) 68.675 ms 68.636 ms 68.691 ms 8 192.168.200.186 (192.168.200.186) 70.094 ms 70.356 ms 69.995 ms 9 * * * 10 * * * # * 表示不支持 traceroute 追踪。 11 * * * 12 * * * 13 * * * 14 * * * 15 * * * 16 * * * 17 * * * 18 * * * 19 * * * 记录按序列号从 1 开始，每个纪录就是一跳 ，每跳表示一个网关，可以看到每行有三个时间，单位是 ms，之所以是 3 个，其实就是 -q 的默认参数。\n探测数据包向每个网关发送三个数据包后，记录网关响应后返回的时间。","什么是路由#什么是路由？":"它是一套双向规则，既扮演着“迎宾员”的角色，决定如何接收外来数据包；也扮演着“导航员”的角色，决定如何发送外出数据包。","使用场景#使用场景":"用于检查哪些端口已开放并正在等待连接：\nsudo ss -tunlp # -t: TCP, -u: UDP, -n: 不解析, -l: 监听, -p: 显示进程 # 输出 # 一眼就能看出：Nginx（PID 1234）在监听 80 端口，SSH（PID 5678）在监听 22 端口 Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port tcp LISTEN 0 128 *:80 *:* users:((\"nginx\",pid=1234,fd=6)) tcp LISTEN 0 128 *:22 *:* users:((\"sshd\",pid=5678,fd=3)) # 查看所有活跃的网络连接 ss -tna | grep ESTAB # 或者更精确地，查看所有已建立连接 ss -t state established 当服务器出现性能问题或怀疑连接数过多时：\nss -s # 输出列解读： Total: 1234 (kernel 0) # TCP 行：可以快速了解当前连接状态分布（已建立、关闭、等待释放等） TCP: 1456 (estab 234, closed 1100, orphaned 5, timewait 1100) Transport Total IP IPv6 * 0 - - RAW 1 0 1 UDP 20 18 2 TCP 356 350 6 INET 377 368 9 FRAG 0 0 0 排查特定服务或端口的问题：\n# 1. 查看谁在连接我的MySQL服务（3306端口） ss -tn dst :3306 # 2. 查看我的Web服务器（80端口）正在与哪些客户端建立连接 ss -tn src :80 # 3. 查看某个IP地址（如 192.168.1.15）与我的所有连接 ss -tn dst 192.168.1.15 # 分析TCP连接内部状态 # 显示TCP连接的详细状态，包括计时器信息（重传超时等） ss -tno # 显示更详细的内部信息，包括拥塞窗口、往返时间等 ss -tni","使用场景-1#使用场景":"# 精确定位网络丢包和抖动问题（最核心的场景） # 运行后，观察哪一跳的 Loss% 开始出现并持续存在（而不是仅在最后一跳），这里就是问题点。 mtr -n baidu.com # 向目标发送100个包后生成报告 # 网络不稳定时，运行一段时间（几分钟）的 mtr，将报告保存下来，作为向运营商报障的有力证据。 mtr -r -c 100 -n example.com \u003e mtr_report.log # 只显示最重要的列：丢包率、平均延迟、最佳延迟、最差延迟 mtr -r -c 50 -o \"L ABW\" -n 203.0.113.10 有些网络设备会限速或优先处理数据包而非 ICMP 应答，导致中间节点显示丢包，但最终目标不丢包。这就需要经验来判断是真实丢包还是设备策略。","分组#分组":"如果要抓取：来源 ip 为 10.211.55.10 且目标端口为 3306 或 6379 的包，如果按照下面的方式写，就会报错：\ntcpdump -i any src 10.211.55.10 and (dst port 3306 or 6379) 因为 () 是不允许的。这时候可以使用单引号 ' 把复杂的组合条件包起来：\ntcpdump -i any 'src 10.211.55.10 and (dst port 3306 or 6379)'","只抓取-5-个报文#只抓取 5 个报文":"使用 -c number 命令可以抓取 number 个报文后退出。\ntcpdump -i any -nn port 80 -c 5","如何查看到目标主机的网络状态#如何查看到目标主机的网络状态":"使用 ping 查看网络是否是通的。 traceroute 和 mtr 辅助 ping 命令，在 ping 通网络之后，如果网络通信还是有问题， 可以使用 traceroute 可以查看网络中每一跳的网络质量。 mtr 可以检测网络中是否有丢包。 nslookup 查看域名对应的 IP。 如果主机可以连接，但是服务仍然无法访问，使用 telnet 检查端口状态。 如果端口没有问题，仍然无法访问，可以使用 tcpdump 进行抓包，更细致的查看网络问题。 使用 netstat 和 ss，查看服务范围。","常用命令示例及其原理#常用命令示例及其原理":"命令示例 工作原理 ip route add default via 192.168.1.1 添加默认路由。将所有未知流量导向网关 192.168.1.1。 ip route add 10.1.0.0/16 via 192.168.1.2 添加静态路由。将所有去往 10.1.0.0/16 的流量交给下一跳路由器 192.168.1.2。 ip route del 10.1.0.0/16 删除一条静态路由。 ip route replace default via 192.168.1.254 替换现有默认路由。将默认网关从之前的改为 192.168.1.254。 ip route get 8.8.8.8 模拟路由查询，诊断“网络不通”问题。显示内核是如何路由到 8.8.8.8 的，用于调试。","显示所有的-rst-包#显示所有的 RST 包":"tcpdump 'tcp[13] \u0026 4 != 0' TCP 首部中 offset 为 13 的字节的第 3 比特位就是 RST。tcp[13] 表示 tcp 头部中偏移量为 13 字节。!=0 表示当前 bit 置 1，即存在此标记位，跟 4 做与运算是因为 RST 在 TCP 的标记位的位置在第 3 位(00000100)。","显示绝对序号#显示绝对序号":"默认情况下，tcpdump 显示的是从 0 开始的相对序号。如果想查看真正的绝对序号，可以用 -S 选项。\n# 没有 -S tcpdump -i any port 80 -nn 12:12:37.832165 IP 10.211.55.10.46102 \u003e 36.158.217.230.80: Flags [P.], seq 1:151, ack 1, win 229, length 150 12:12:37.832272 IP 36.158.217.230.80 \u003e 10.211.55.10.46102: Flags [.], ack 151, win 16384, length 0 # 加了 -S tcpdump -i any port 80 -nn -S 12:13:21.863918 IP 10.211.55.10.46074 \u003e 36.158.217.223.80: Flags [P.], seq 4277123624:4277123774, ack 3358116659, win 229, length 150 12:13:21.864091 IP 36.158.217.223.80 \u003e 10.211.55.10.46074: Flags [.], ack 4277123774, win 16384, length 0","禁用主机与端口解析#禁用主机与端口解析":"不加 -n 选项，tcpdump 会显示主机名，比如下面的 test.ya.local 和 c2.shared：\n09:04:56.821206 IP test.ya.local.59915 \u003e c2.shared.ssh: Flags [P.], seq 397:433, ack 579276, win 2048, options [nop,nop,TS val 1200089877 ecr 435612355], length 36 加上 -n 选项以后，可以看到主机名都已经被替换成了 ip：\ntcpdump -i any -n 10:02:13.705656 IP 10.211.55.2.59915 \u003e 10.211.55.10.ssh: Flags [P.], seq 829:865, ack 1228756, win 2048, options [nop,nop,TS val 1203228910 ecr 439049239], length 36 常用端口还是会被转换成协议名，比如 ssh 协议的 22 端口。如果不想 tcpdump 做转换，可以加上 -nn，这样就不会解析端口了，输出中的 ssh 变为了 22：\ntcpdump -i any -nn 10:07:37.598725 IP 10.211.55.2.59915 \u003e 10.211.55.10.22: Flags [P.], seq 685:721, ack 1006224, win 2048, options [nop,nop,TS val 1203524536 ecr 439373132], length 36","网络诊断#网络诊断":"","路由查询过程#路由查询过程":"当内核需要发送一个数据包时，是如何使用这张表的呢？这个过程称为路由查找 (Route Lookup)，它遵循最长前缀匹配 (Longest Prefix Match) 原则：\n数据包目标 IP：例如 192.168.0.150。 查询路由表：内核逐条比对路由条目中的“目标网络”。 匹配： 它会同时匹配 192.168.0.0/24 (24 位前缀) 和 default / 0.0.0.0/0 (0 位前缀)。 根据最长前缀匹配原则，/24 比 /0 更具体、更长，因此优先级更高。 执行：内核选择 192.168.0.0/24 dev eth0 这条路由，直接将数据包从 eth0 接口发出，而无需经过网关。","路由表的结构与查看#路由表的结构与查看":"直接输入 ip route show（或简写为 ip r）可以查看当前的路由表。它的结构由一系列路由条目组成，每个条目包含以下几个关键部分：\n部分 含义 示例 解释 Destination (目标网络) 数据包要去的IP网段 192.168.1.0/24 这条规则适用于去往 192.168.1.x 的所有包 via (网关/Gateway) 下一跳路由器的IP地址 via 192.168.0.1 把数据包发给这个地址（路由器）去处理 dev (接口/Device) 数据包应该从哪个网络接口发出 dev eth0 数据包从 eth0 网卡发出 proto (协议/Protocol) 此路由条目的来源 proto kernel 由内核自动生成（直连路由） scope (作用域) 路由的有效范围 scope link 仅适用于直连链路 metric (度量值) 路由的优先级（成本） metric 100 值越小，优先级越高 ip route show 示例：\ndefault via 192.168.0.1 dev eth0 proto dhcp metric 100 192.168.0.0/24 dev eth0 proto kernel scope link src 192.168.0.100 metric 100 local 192.168.0.100 dev eth0 proto kernel scope host src 192.168.0.100 默认路由 (Default Route)：default via 192.168.0.1 dev eth0 proto dhcp metric 100。 所有发往非本机、非直连网络的数据包（即不知道往哪扔的包），都通过 eth0 网卡发给网关 192.168.0.1。 default 是 0.0.0.0/0 的简写。 proto dhcp 表示这个路由是通过 DHCP 动态获取的。 metric 100 表示这个路由的优先级是 100，数值越小，优先级越高。 直连路由 (Direct Route)：192.168.0.0/24 dev eth0 proto kernel scope link src 192.168.0.100 metric 100。 发往 192.168.0.0/24 这个网段的数据包，直接通过 eth0 网卡发出，不需要网关。src 指明了从本机发出数据包时，默认使用的源 IP 地址。 当你为网卡配置 IP 地址并启动时（如 ip addr add 192.168.0.100/24 dev eth0），内核会自动生成对应的直连路由。 意思就是，这个包是局域网内的包，不需要通过网关发送了，所以没有 via。 本地路由 (Local Route)：local 192.168.0.100 dev eth0 proto kernel scope host src 192.168.0.100。 这条路由通常不会在 ip route show 中直接显示，需要使用 ip route show table local 查看。它管理发往本机自身 IP 的数据包。 local：关键字。明确标识这是一条本地路由，与普通路由的网段格式（如 192.168.0.0/24）不同。 192.168.0.100：目标地址。这就是本机配置的 IP 地址。它是一个精确的主机路由（/32），而不是一个网段。 scope host：作用域。这是最关键的部分！scope host 意味着这条路由仅在本机内部有效，绝不可能被转发到网络上去。它划清了一条清晰的边界：这是“我自己”。 proto kernel：协议。由内核自动生成。","输出-ascii-格式#输出 ASCII 格式":"-A 用 ASCII 打印报文内容：\ntcpdump -i any -nn port 80 -A 11:04:25.793298 IP 183.57.82.231.80 \u003e 10.211.55.10.40842: Flags [P.], seq 1:1461, ack 151, win 16384, length 1460 HTTP/1.1 200 OK Server: Tengine Content-Type: application/javascript Content-Length: 63522 Connection: keep-alive Vary: Accept-Encoding Date: Wed, 13 Mar 2019 11:49:35 GMT Expires: Mon, 02 Mar 2020 11:49:35 GMT Last-Modified: Tue, 05 Mar 2019 23:30:55 GMT ETag: W/\"5c7f06af-f822\" Cache-Control: public, max-age=30672000 Access-Control-Allow-Origin: * Served-In-Seconds: 0.002","输出到文件#输出到文件":"tcpdump -i any port 80 -w test.pcap 生成的 pcap 文件就可以用 wireshark 打开进行更详细的分析。","过滤-syn--ack-包#过滤 SYN + ACK 包":"tcpdump 'tcp[13] \u0026 18 != 0'","过滤主机#过滤主机":"如果只想查看 ip 为 10.211.55.2 的网络包，这个 ip 可以是源地址也可以是目标地址：\ntcpdump -i any host 10.211.55.2","过滤协议#过滤协议":"只查看 udp 协议：\ntcpdump -i any -nn udp 10:25:31.457517 IP 10.211.55.10.51516 \u003e 10.211.55.1.53: 23956+ A? www.baidu.com. (31) 10:25:31.490843 IP 10.211.55.1.53 \u003e 10.211.55.10.51516: 23956 3/13/9 CNAME www.a.shifen.com., A 14.215.177.38, A 14.215.177.39 (506)","过滤指定端口范围内的流量#过滤指定端口范围内的流量":"抓取 21 到 23 区间所有端口的流量：\ntcpdump portrange 21-23","过滤源地址目标地址#过滤源地址、目标地址":"只抓取源地址是 10.211.55.11 的包：\ntcpdump -i any src 10.211.55.11 只抓取目标地址为 10.211.55.11 的包：\ntcpdump -i any dst 10.211.55.11","过滤端口#过滤端口":"只抓取某个端口的数据包，比如查看 80 端口的数据包：\ntcpdump -i any port 80 只想抓取目标端口为 80 的数据包，也就是 80 端口收到的包，可以加上 dst：\ntcpdump -i any dst port 80","运算符#运算符":"tcpdump 可以用布尔运算符 and（\u0026\u0026）、or（||）、not（!）来组合出任意复杂的过滤器。\n# 抓取 ip 为 10.211.55.10 并且目的端口为 3306 的数据包 tcpdump -i any host 10.211.55.10 and dst port 3306 # 抓取源 ip 为 10.211.55.10，目标端口除了 22 以外所有的流量 tcpdump -i any src 10.211.55.10 and not dst port 22","运维工作流#运维工作流":"# 1. 使用 mtr 进行初步诊断，定位问题范围 # 使用 --tcp 和 -p 443 是为了模拟真实的 HTTPS 流量，更有可能穿透防火墙 # 观察几十秒到一分钟 # 发现：在第 8 跳（某个国际出口路由器）之后，Loss% 上升到 15%，Wrst 延迟超过 500ms。 mtr -n --tcp -p 443 example.com # 2. 使用 traceroute 快速确认路径 traceroute -n -p 443 example.com # 3. 得出结论并提供证据 # 问题出在出国链路的第 8 跳节点附近，存在严重丢包和高延迟。 # 保存 mtr 报告截图或文本 mtr 是绝大多数情况下的首选。当你需要诊断网络慢、抖动、断线等质量问题时，优先使用 mtr。它能提供持续的数据，让你清晰看到丢包和延迟发生在哪一跳。 当你只需要快速看一眼路由路径是否正常，或者在脚本中调用时，使用 traceroute。它的输出更简单，更适合自动化处理。","限制包大小#限制包大小":"当包体很大，可以用 -s 截取部分报文内容，一般和 -A 一起使用。\n# 查看每个包体前 500 字节 tcpdump -i any -nn port 80 -A -s 500 显示包体所有内容，可以加上 -s 0。"},"title":"网络"},"/devops-learn/docs/linux/09_git/":{"data":{"":"","gh#gh":"gh 是 GitHub CLI（命令行工具），可以直接在命令行中执行常见的 GitHub 操作（如创建仓库、PR、Issue、Review、Actions 等），非常适合 DevOps 或日常运维自动化使用。","git#git":"Git 命令的一些使用技巧。","issue-管理#Issue 管理":"# 创建 Issue gh issue create --title \"API bug\" --body \"Detail about bug\" # 查看 Issue 列表 gh issue list # 查看 Issue 详情 gh issue view 42 gh issue view 42 --web # 关闭 Issue gh issue close 42 # 重新打开 Issue gh issue reopen 42 Actions：\n# 查看最近的 workflow 运行 gh run list # 查看运行详情 gh run view 123456789 # 打开 workflow 运行网页 gh run view 123456789 --web # 重新运行 workflow gh run rerun 123456789 # 取消运行 gh run cancel 123456789 # 下载 workflow 日志 gh run download 123456789","pull-request-管理#Pull Request 管理":"# 创建 PR（当前分支 -\u003e main） gh pr create --base main --title \"Fix bug\" --body \"Bug details...\" # 查看 PR 列表 gh pr list # 查看单个 PR 详情 gh pr view 123 gh pr view 123 --web # 打开网页查看 # 合并 PR gh pr merge 123 # 默认创建 merge commit gh pr merge 123 --squash # squash 合并 gh pr merge 123 --rebase # rebase 合并 # 检出某个 PR（拉取分支进行测试） gh pr checkout 123 # 关闭 PR gh pr close 123","release-与-tag-管理#Release 与 Tag 管理":"# 创建 release gh release create v1.0.0 --title \"v1.0.0\" --notes \"Initial release\" # 附加文件 gh release create v1.0.0 ./build/app.tar.gz # 查看 release 列表 gh release list # 查看 release 详情 gh release view v1.0.0 # 删除 release gh release delete v1.0.0","仓库管理#仓库管理":"# 创建一个新仓库（本地 + 远程） gh repo create my-repo --public # 只在 GitHub 上创建仓库 gh repo create my-repo --public --confirm --source=. # 克隆仓库（替代 git clone） gh repo clone user/repo # 打开当前仓库的 GitHub 页面 gh repo view --web # 查看仓库信息 gh repo view user/repo # Fork 仓库 gh repo fork user/repo # 删除远程仓库 gh repo delete user/repo","安装与认证#安装与认证":"# 安装（macOS） brew install gh # 登录 GitHub（支持 Web 登录或 Token） gh auth login # 查看当前登录信息 gh auth status # 退出登录 gh auth logout","常见运维场景#常见运维场景":"自动重跑失败的 Actions：\ngh run list --limit 10 --json databaseId,status | jq -r '.[] | select(.status==\"failure\") | .databaseId' | xargs -n1 gh run rerun 快速打开 PR 或 Issue：\ngh pr view --web gh issue view 101 --web"},"title":"Git"},"/devops-learn/docs/linux/10_nfs/":{"data":{"":"NFS 在 Linux 中会默认安装。","root_squash-是什么为什么会有-permission-denied#root_squash 是什么？为什么会有 Permission denied？":"root_squash 的作用：将客户端上使用 root 用户（UID=0）发出的所有请求，映射（“压缩”）到服务器上的一个非特权用户（通常是 nobody 或 nfsnobody）。\n设计目的：这是极其重要的安全措施。如果没有它，任何在客户端拥有 root 权限的用户都可以在 NFS 共享上以 root 身份为所欲为，完全绕过服务器上的文件权限检查，造成巨大的安全风险。\n触发场景：\n你在客户端直接使用 sudo 或 su root 操作挂载点。 某个服务或进程以 root 身份运行并尝试写入 NFS。 简单来说：root_squash 故意拒绝了客户端 root 用户的权限，以防止安全漏洞。\n例如：\n# /etc/exports 配置如下 /nfs_share 192.168.1.0/24(rw,sync,root_squash) 在客户端（UID=0）执行：sudo touch /mnt/nfs/test_file 请求到达 NFS 服务器。 root_squash 机制将客户端的 UID=0 映射为服务器上的 UID=65534（nobody 用户）。 服务器尝试以 nobody 用户的身份在 /nfs_share 目录创建文件。 如果服务器上的 /nfs_share 目录不属于 nobody 用户，且也没有给“其他用户”（others）写权限，那么操作就会失败，并返回 Permission denied。 解决方案：\n在客户端使用合适的普通用户不要使用 sudo 或 root 用户来访问 NFS 挂载点。使用一个普通用户，并确保该用户在服务器端也有相应的权限。这通常需要统一UID/GID 或使用下一个方案。\n使用 all_squash 并指定固定用户（最常用、最安全）这是处理多个客户端、多个用户情况下的最佳实践。它将所有客户端用户（包括 root）都映射到服务器上的同一个特定用户。\n# 在 NFS 服务器上 # 1. 创建一个专门用于 NFS 共享的用户（如果还没有） sudo useradd -r -s /bin/false -M nfsuser # 2. 查看它的 UID 和 GID（例如是 1001:1001） id nfsuser # 3. 将共享目录的所有者改为这个用户 sudo chown -R nfsuser:nfsuser /nfs_share sudo chmod -R 755 /nfs_share # 或 775 如果需要组写权限 # 修改 /etc/exports，使用 all_squash 并明确指定 UID/GID /nfs_share 192.168.1.0/24(rw,sync,all_squash,anonuid=1001,anongid=1001) # 使配置生效 sudo exportfs -ra 现在，无论客户端用什么用户（root 还是普通用户）写文件，在服务器上都会显示为 nfsuser 用户创建的。由于目录所有者就是 nfsuser，写入自然成功。","常用命令#常用命令":"# 使配置生效 # 通用命令（CentOS 7/8, Rocky Linux, AlmaLinux） # -a：全部（export 所有 / 取消 export 所有） # -r：重新 export（重新读取 `/etc/exports`） # -v：显示详细信息 exportfs -arv # 或者重启服务（较老系统） systemctl restart nfs-server # 或 nfs-kernel-server # 查看当前共享状态 exportfs -v showmount -e localhost # 查看本机共享了哪些目录 # 示例：查看192.168.1.10上共享的目录 showmount -e 192.168.1.10 # 临时挂载（重启后失效） mount -t nfs :/ / # 示例：将服务端的 /data 挂载到本地的 /mnt/nfs_data mount -t nfs 192.168.1.10:/data /mnt/nfs_data # 永久挂载 （配置 /etc/fstab） # 在 `/etc/fstab` 文件中添加一行，实现开机自动挂载。 # 添加配置后，执行 mount -a 命令来挂载所有在 fstab 中定义的文件系统，测试配置是否正确 # defaults，通用的选项集合，对于生产环境，可能会根据需要替换为更具体的选项，例如 rsize=8192,wsize=8192 # 第一个 0，这个字段被 dump 命令用来决定是否需要备份这个文件系统，0 表示：忽略，不备份 # 第二个 0，系统启动时，fsck 程序会用它来决定检查文件系统的顺序，0 表示：不检查。对于网络文 # 件系统（NFS）、虚拟文件系统或者非根磁盘，必须设置为0。根文件系统通常设置为1，表示优先检查。 :/ / nfs defaults 0 0 # 示例： 192.168.1.10:/data /mnt/nfs_data nfs defaults 0 0 # 卸载NFS共享目录 umount / # 示例：卸载 /mnt/nfs_data umount /mnt/nfs_data # 查看已挂载的NFS共享 mount -t nfs # 只显示NFS类型的挂载 df -hT # 显示所有文件系统，包括类型和挂载点","常见问题#常见问题":"连通性排查：\n# 1. 检查网络是否通 ping # 2. 检查 NFS 服务端口（2049）是否开放 telnet 2049 权限排查（最常见的问题）：\n问题：客户端无法写入文件，提示 Permission denied。\n原因：服务端和客户端的用户 UID/GID 不匹配，或者 /etc/exports 选项配置过于严格（如 root_squash）。\n排查：\n在客户端和服务端同时执行 id ，检查相同用户名的 UID 和 GID 是否一致。 检查服务端共享目录的本地文件权限：ls -ld /shared/directory 检查服务端 /etc/exports 的选项，是否使用了 all_squash 或 root_squash。 挂载点排查：\n问题：挂载失败\n# 查看详细的挂载错误信息 mount -v :/data /mnt/nfs_data # 查看系统日志，获取错误线索 tail -f /var/log/messages # CentOS/RHEL tail -f /var/log/syslog # Ubuntu/Debian 性能排查：\n问题：NFS 读写速度慢\n尝试在挂载时使用 async 选项（牺牲安全性换取性能）。 检查网络带宽和延迟。 使用 nfsiostat（类似 iostat）工具查看 NFS 挂载点的 IO 性能指标。","配置文件#配置文件":"NFS 的主配置文件：/etc/exports。\n[root@SGDLITVM0905 ~]# cat /etc/exports /data/share *(rw,sync,all_squash) /data/share2 10.222.77.0/24(rw,sync,insecure,no_subtree_check,no_root_squash) /var/vols/itom/core *(rw,sync,anonuid=1999,anongid=1999,root_squash) ... 格式：\n\u003c共享的目录路径\u003e \u003c客户端IP或网段(选项1,选项2,...)\u003e # 共享 /data 目录给 192.168.1.0/24 网段，可读写，并压缩 root 权限 /data 192.168.1.0/24(rw,sync,root_squash) # 共享 /backup 目录给特定 IP 192.168.1.100，只读，所有用户映射为 UID=1001 的用户 /backup 192.168.1.100(ro,all_squash,anonuid=1001,anongid=1001) 常用选项：\nro：只读访问，共享静态数据，如软件包、配置文件。 rw：读写访问，需要客户端写入数据的共享目录。 sync：同步写入，数据更安全，但性能较低（默认）。请求完成后才写入磁盘。 async：异步写入，性能更高，但风险更大。先响应请求，再写入磁盘。 no_root_squash：信任 root 用户，危险！客户端的 root 用户在服务端也拥有 root 权限。 root_squash：安全！客户端的 root 用户被映射为服务端的匿名用户（nfsnobody）。 all_squash：所有客户端用户都映射为匿名用户，适用于公共目录。 anonuid/anongid：指定匿名 UID/GID 与 all_squash 配合，指定映射到的具体用户 ID 和组 ID。"},"title":"NFS"},"/devops-learn/docs/linux/11_perms/":{"data":{"":"","setuid-suid-的作用是什么#SetUID (SUID) 的作用是什么？":"当一个可执行文件被设置了 SetUID 位后：任何用户在执行这个文件时，其有效用户 ID (Effective UID) 将在程序运行期间临时变更为这个文件的所有者（user）的 ID，而不是执行它的用户的 ID。\n4 = SetUID (Set User ID) 仅用二进制于可执行文件，执行者将具有该文件的所有者的权限。 2 = SetGID (Set Group ID) 执行者将具有该文件的所属用户组的权限。 1 = SBIT (Sticky Bit) 仅用于目录，用来阻止非文件的所有者删除文件，仅有自己和 root 才有权力删除。 例如：\n-rwsr-xr-x 1 root root 63960 Feb 7 2023 /usr/bin/passwd # SGID # s 出现在用户组的 x 权限的位置，执行者将具有该文件的所属用户组的权限。 -rwxr-sr-x. 1 root mlocate 39832 Jan 30 2014 /usr/bin/mlocate* # SBIT # rwt 里的 t 就表示该文件仅 root 和自己可以删除 drwxrwxrwt. 14 root root 4096 Aug 18 20:11 tmp 权限位中的 s（在用户执行位的 x 位置上）。这个 s 就是 SetUID 位的可视化表示。它表示这个文件具有 SetUID 权限，并且所有者是 root。\n普通用户（如 alice）没有权限直接修改受保护的 /etc/shadow 文件（该文件只有 root 可写）。 但当 alice 执行 passwd 命令时，由于 SetUID 位的存在，这个进程会临时获得 root 权限。 此时，passwd 命令就可以以 root 身份去写入 /etc/shadow 文件，从而成功修改 alice 自己的密码。 命令执行结束后，进程结束，临时获得的 root 权限也随之消失。 如果没有 SetUID 位，passwd 命令就会以普通用户 alice 的权限运行，尝试写入 /etc/shadow 时会被拒绝，导致密码修改失败。\n重要提示：如果文件所有者没有执行权限（x），当你设置 SetUID 位时，ls -l 会显示为大写的 S（例如 rwSr-xr-x），这表示 SetUID 位虽然设置了，但因为缺少执行权限，所以是无效的。","visudo#visudo":"su 切换到 root 需要使用密码。如果普通用户想要使用 root 权限，就需要密码。这是有风险的。因此出现了 sudo。\nsudo 可以使 root 去权限，有针对性的给指定的普通用户权限，并且不需要密码。使用 sudo 的前提是配置 /etc/sudoers 文件来授权。\nvisudo 用来编辑 /etc/sudoers：\n## Allows people in group pooky to run all commands # %pooky 表示 pooky 用户组，如果要表示 pooky 用户，则去掉 % %pooky ALL=(ALL) ALL ## Without a password %pooky ALL=(ALL) NOPASSWD: ALL ## Allows members of the users group to mount and unmount the cdrom as root %users ALL=/sbin/mount /mnt/cdrom, /sbin/unmount /mnt/cdrom ## Allows members of the usrs froup to shutdown this system %users localhost=/sbin/shutdown -h now","修改文件权限#修改文件权限":"chmod：修改文件，目录的权限。\nu，用户，对应 rwxr-xr-x 这 9 个字符中的前三个字符。 g，用户组，对应 rwxr-xr-x 这 9 个字符中的中间三个字符。 o，其他用户，对应 rwxr-xr-x 这 9 个字符中的后面三个字符。 a，所有用户，默认。 +，增加权限。 -，删除权限。 =，设置权限。 -R，参数表示递归目录下所有文件和子目录。 chmod u+x file # file 所属用户增加执行权限 chmod 751 file # file 所属用户分配 rwx(7) 权限，所在组分配 rx(5) 权限，其他用户分配 x(1) 权限 chmod u=rwx,g=rx,o=x file # 上例的另一种形式 chmod =r file # 为所有用户分配读权限，也就是 a=r chmod 444 file # 同上例 chmod a-wx,a+r file # 同上例 chmod -R u+r directory # 递归地给 directory 目录下所有文件和子目录的属主分配读的权限 chmod 4755 # 4 表示要设置 SetUID 位，755 是标准的权限设置","文件权限#文件权限":"","查看文件权限#查看文件权限":"ls -l 可以查看文件权限：\n# - 表示普通文件 # rwxr-xr-x 这 9 个字符表示权限， # 前面 3 个字符 rwx 表示当前用户的权限 # 中间 3 个字符 r-x 表示所属用户组的权限 # 后 3 个字符 r-x 表示其他用户的权限 -rwxr-xr-x. 1 root root 12059203 Jun 12 2019 renewCert","用户切换#用户切换":"su：切换用户 su - user1，切换到 user1，- 表示同时切换用户环境。 exit 退回上个用户。 sudo：以 root 身份执行命令。","用户和用户组的配置文件#用户和用户组的配置文件":"/etc/passwd 是用户的配置文件，竟然用的密码文件！！真正的密码在 /etc/shadow 文件中！！\n# 用户名:是否需要密码验证:UID:GID:注释:用户 home 目录:用户登录使用的命令解释器 # root:x 中 x 表示此用户有密码 root:x:0:0:root:/root:/bin/bash # /sbin/nologin 表示不允许登录 bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin # ... 可以直接编辑这个文件来新建用户。比如添加一行 user1:x:1000:1000::/home/user1:/bin/bash，用户 home 目录需要手动创建。\n可以修改 UID 来修改权限，比如把 UID 改为 0，用户就会拥有 root 权限。\n/etc/shadow 保存用户和密码信息，此文件只有 root 用户可以浏览和操作。\n# 用户名:加密的密码: root:$6$PcVZ4yj4vlMjqmkL$RUHwggR7gPD0SnjTF1WnStHi2If0hSJnc4M/oVTfD0omJxVGhQgnQhBKRNPiwcBSeL72IerSphnEVdaomgjx./::0:99999:7::: bin:*:17492:0:99999:7::: daemon:*:17492:0:99999:7::: # ... /etc/group 是用户组配置文件：\n# 用户组名:是否需要密码验证:GID:用户组中的用户列表 root:x:0: bin:x:1: daemon:x:2: daemon2:x:3:bin,daemon2 # ...","用户管理#用户管理":"useradd： useadd pooky，添加用户，默认情况下会自动创建同名 group。 -g：useradd -g group1 pooky，添加用户并加入到用户组 -M：不要自动建立用户的登入目录。 -r：建立系统账号。 -s：指定用户登入后所使用的 shell。默认值为 /bin/bash。/bin/false 禁止用户登录, 用户不会收到任何错误或提示信息。/sbin/nologin 当被用作用户的登录 shell 时，它会显示一条拒绝登录的消息（通常是一行文本），然后结束会话。 id pooky：验证用户是否存在 userdel：删除用户 userdel pooky 删除用户 pooky。 -r：会删除用户的 home 目录 passwd: 修改密码 passwd pooky 设置用户 pooky 的密码。 只运行 passwd 命令，不提供用户，就会修改当前用户的密码。 usermod：修改用户属性 -a: 追加组，如果想要保留用户的组，并添加新组时使用。 -d：修改用户 home 目录，usermod -d /hmoe/pookyh pooky 把 pooky 的 home 目录改为 pookyh。 -g：修改用户组。usermod -g group1 pooky 将 pooky 的用户组改为 group1。","用户组#用户组":"groupadd：创建用户组 groupdel：删除用户组"},"title":"用户和权限管理"},"/devops-learn/docs/linux/12_systemctl/":{"data":{"":"Systemd 管理的对象称为 Unit，每个 Unit 都有一个对应的配置文件。\n.service：服务（最常用），如 nginx, mysql, docker。 .socket：套接字。 .mount：挂载点。 .timer：定时任务（替代 cron）。 命令：\nsystemctl start \u003c服务名\u003e：启动一个服务，部署新应用后启动服务。 systemctl stop \u003c服务名\u003e：停止一个服务，需要紧急停止服务时。 systemctl restart \u003c服务名\u003e：重启一个服务，修改配置文件后，使配置生效。 systemctl reload \u003c服务名\u003e：重载一个服务，让服务重新加载配置而不中断当前连接（如 nginx）。 systemctl reload-or-restart \u003c服务名\u003e：能重启，如果服务支持 reload 则 reload，否则 restart。 systemctl status \u003c服务名\u003e：查看服务的详细状态（最常用），故障排查第一步。查看服务是否活跃、是否有错误日志、进程 ID 等。 systemctl is-active \u003c服务名\u003e：检查服务是否正在运行，在脚本中判断服务状态，返回 active 或 inactive。 systemctl is-enabled \u003c服务名\u003e：检查服务是否开机自启，在脚本中判断服务启动模式，返回 enabled 或 disabled， systemctl is-failed \u003c服务名\u003e：检查服务是否启动失败，检查服务是否处于故障状态，返回 failed 或 active。 systemctl enable \u003c服务名\u003e：启用开机自动启动，安装新服务后，必须设置以保证服务器重启后服务能自动运行。 systemctl disable \u003c服务名\u003e：禁用开机自动启动。 systemctl mask \u003c服务名\u003e：屏蔽服务（无法手动或自动启动）彻底禁用一个服务，防止被意外启动（比 disable 更彻底）。 systemctl unmask \u003c服务名\u003e：取消屏蔽服务。 systemctl daemon-reload：重载 Systemd 配置，修改了服务的配置文件（.service 文件）后，必须执行此命令， 让 Systemd 识别新的配置。注意：这与 reload 服务不同。 systemctl list-units --type=service：列出所有已加载的服务及其状态。 systemctl list-unit-files --type=service：列出所有服务的开机启动状态。 systemctl cat \u003c服务名\u003e：显示服务的配置文件内容，快速查看服务的配置，而不用去找文件位置。 systemctl edit \u003c服务名\u003e：编辑服务配置（会创建覆盖片段），修改服务配置的推荐方式，避免直接修改主配置文件， systemctl reboot：重启系统，安全的系统重启方式。 systemctl poweroff：关闭系统，安全的系统关机方式。 查看服务状态：\npooky@DESKTOP-DMAGDPE:~$ systemctl status cron ● cron.service - Regular background program processing daemon Loaded: loaded (/usr/lib/systemd/system/cron.service; enabled; preset: enabled) Active: active (running) since Fri 2025-08-22 11:01:51 CST; 1 day 5h ago Docs: man:cron(8) Main PID: 164 (cron) Tasks: 1 (limit: 16586) Memory: 1.2M (peak: 4.9M) CPU: 2.054s CGroup: /system.slice/cron.service └─164 /usr/sbin/cron -f -P Loaded：单元配置文件位置，以及是否开机启动（enabled）。 Active：当前状态，如 active (running)（运行中）、inactive (dead)（未运行）、failed（失败）。 Main PID：主进程ID。 CGroup：CGroup 信息，包含相关进程。 日志片段：最后几条相关日志，对排查故障极其重要。"},"title":"Systemd"},"/devops-learn/docs/linux/13_sar/":{"data":{"":"","sar#sar":"sar（System Activity Reporter，系统活动报告器）是 Linux 运维中功能最强大的系统性能历史数据查询和分析工具之一。由 sysstat 软件包提供，通过定期收集系统性能数据，让你可以在故障发生后回溯历史，查看当时的系统状态。\n[root@pooky ~]# sar -u 1 10 Linux 3.10.0-862.el7.x86_64 (pooky.hpeswlab.net) 09/01/2020 _x86_64_ (8 CPU) 09:06:43 PM CPU %user %nice %system %iowait %steal %idle 09:06:44 PM all 0.13 0.00 0.13 0.00 0.00 99.75 09:06:45 PM all 0.38 0.00 0.13 0.00 0.00 99.50 09:06:46 PM all 0.25 0.00 0.37 0.00 0.00 99.38 09:06:47 PM all 0.13 0.00 0.00 0.00 0.00 99.87 09:06:48 PM all 0.12 0.00 0.25 0.00 0.00 99.62 09:06:49 PM all 0.88 0.00 0.63 0.00 0.00 98.50 09:06:50 PM all 0.25 0.00 0.13 0.00 0.00 99.62 09:06:51 PM all 0.25 0.00 0.13 0.00 0.00 99.62 09:06:52 PM all 0.13 0.00 0.00 0.00 0.00 99.87 09:06:53 PM all 0.25 0.00 0.13 0.00 0.00 99.62 Average: all 0.28 0.00 0.19 0.00 0.00 99.54","常用参数与语法#常用参数与语法":"sar -u 1 10 中 -u 表示查看 cpu 状态。1 表示采样时间间隔，10 表示采样次数。 -r 查看内存。 -b 查看 IO。 -d 查看磁盘。 -q 查看进程。"},"title":"系统状态"},"/devops-learn/docs/linux/14_dns/":{"data":{"":"","dig#dig":"dig example.com # 或者指定记录类型 dig A example.com dig MX example.com # 查询邮件服务器 dig NS example.com # 查询权威DNS服务器 dig TXT example.com # 查询TXT记录（常用于验证、SPF等） # 使用Google的公共DNS查询，验证解析是否正确 dig @8.8.8.8 example.com # 查询公司内部的DNS服务器，看内部解析是否正常 dig @192.168.1.10 example.com # 直接向域名的权威DNS服务器查询，得到最准确的结果 dig @ns1.cloudflare.com example.com # 反向DNS解析：通过IP地址查询域名（PTR记录）。 dig -x 8.8.8.8","etcresolvconf#/etc/resolv.conf":"/etc/resolv.conf 文件的主要作用是配置系统使用的 DNS 解析器（Resolver）。它告诉系统：\n应该向哪些 DNS 服务器发送查询请求。 如何对待本地域名（short name）。 查询的搜索域（search domain） 顺序。 例如：\n# 完整配置 # This file is managed by man:systemd-resolved(8). Do not edit. # 或者是由 NetworkManager、DHCP 客户端管理的提示 # 指定DNS服务器 nameserver 192.168.1.1 nameserver 8.8.8.8 # 指定搜索域 search mydomain.com internal.mydomain.com # 解析器选项 options timeout:2 attempts:2 nameserver：指定 DNS 服务器地址： 最多可以指定 3 个 nameserver，系统会按顺序尝试查询。 建议至少配置两个，以保证高可用性。 可以指向公共 DNS（如 8.8.8.8）、本地网络中的 DNS 服务器（如路由器 192.168.1.1）或自己搭建的 DNS 缓存服务器。 nameserver 192.168.1.1 # 本地路由器/网关 nameserver 8.8.8.8 # Google 公共 DNS（主） nameserver 1.1.1.1 # Cloudflare 公共 DNS（备） domain/search：指定搜索域。这两个指令用于配置不完全限定域名（非 FQDN）的搜索方式。当你输入 ping web01 而不是 ping web01.example.com 时，系统会根据这个设置自动尝试补全域名。 domain：指定本地主机的域名。系统会尝试将主机名补全为 \u003c主机名\u003e.。 search：指定一个域名搜索列表（最多 6 个域，总长度限制）。系统会按顺序依次尝试补全。 domain 和 search 不能同时使用；如果同时存在，则最后出现的一个生效。 # 场景：你的服务器主机名是 server01，完整域名是 server01.prod.example.com # 你想直接 ping 同一域下的其他主机，如 db01 search prod.example.com example.com # 当你执行 `ping db01` 时，系统会依次尝试解析： # 1. db01.prod.example.com # 2. db01.example.com # 3. db01 (最终失败) domain prod.example.com # 效果与 `search prod.example.com` 基本相同 options配置解析器选项： options rotate：在列出的多个 nameserver 之间进行轮询，而不是严格按顺序尝试。这可以实现简单的负载均衡。 options timeout:n：设置等待 DNS 服务器响应的超时时间（n 为秒数，默认通常为 5）。 options attempts:n：设置尝试查询每个 DNS 服务器的次数（默认通常为 2）。","nslookup#nslookup":"# 直接查询 nslookup example.com # 指定DNS服务器查询 nslookup example.com 8.8.8.8 # 进入交互模式（适合连续查询） nslookup \u003e server 8.8.8.8 # 设置要查询的DNS服务器 \u003e set type=MX # 设置查询记录类型 \u003e google.com # 执行查询 \u003e exit # 退出"},"title":"DNS"},"/devops-learn/docs/linux/15_selinux/":{"data":{"":"SELinux 会有三种模式：\nenforcing：强制模式。违反 SELinux 规则的行为将被阻止并记录到日志中。 permissive：宽容模式。违反 SELinux 规则的行为只会记录到日志中。一般为调试用。 disabled：关闭 SELinux。 可以在配置文件 /etc/selinux/config 中配置 SELINUX 的字段。\n# This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=permissive # SELINUXTYPE= can take one of three two values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection. SELINUXTYPE=targeted SELINUXTYPE 是 SELinux 的策略类型。有三种策略，分别是：\ntargeted：对大部分网络服务进程进行管制。系统默认。 minimum：以 targeted 为基础，仅对选定的网络服务进程进行管制。一般不用。 mls：多级安全保护。对所有的进程进行管制。这是最严格的策略，配置难度非常大。一般不用。"},"title":"SELinux"},"/devops-learn/docs/linux/firewall/":{"data":{"":"防火墙分为两类：\n软件防火墙，CentOS 6 的默认防火墙是 iptables，CentOS 7 的默认防火墙是 firewalld，底层都是使用内核中的 netfilter实现的。 包过滤防火墙，主要用于数据包的过滤，数据包转发。 应用层防火墙，可以控制应用程序的具体的行为。 硬件防火墙，例如 Cisco ASA、 Juniper SRX 等。"},"title":"防火墻"},"/devops-learn/docs/linux/firewall/01_iptables/":{"data":{"":"iptables 的核心工作原理可以概括为：“根据规则，对数据包进行过滤或处理”。这些规则被组织在预定义的链（Chains） 和表（Tables） 中。\nTables 由 Chains 组成，而 Chains 又由规则（Rules）组成。","probability#probability":"iptables 的 statistic 模块支持基于概率的规则匹配，通过 --mode random 和 --probability 参数实现随机匹配。此功能常用于负载均衡或流量分配。\niptables -A PREROUTING -t nat -p tcp -d 192.168.1.1 --dport 27017 \\ -m statistic --mode random --probability 0.33 \\ -j DNAT --to-destination 10.0.0.2:1234 iptables -A PREROUTING -t nat -p tcp -d 192.168.1.1 --dport 27017 \\ -m statistic --mode random --probability 0.5 \\ -j DNAT --to-destination 10.0.0.3:1234 iptables -A PREROUTING -t nat -p tcp -d 192.168.1.1 --dport 27017 \\ -j DNAT --to-destination 10.0.0.4:1234 第一条规则有 33% 的概率命中。 第二条规则有 50% × (1 − 33%) = 33% 的概率命中。 第三条规则没有指定 --probability，因此剩余的 34% 流量会命中。","使用场景#使用场景":"# 1. 设置默认策略（最严格的策略） iptables -P INPUT DROP # 默认拒绝所有入站 iptables -P FORWARD DROP # 默认拒绝所有转发 iptables -P OUTPUT ACCEPT # 默认允许所有出站（通常这样设置） # 2. 允许本地回环接口（localhost通信） iptables -A INPUT -i lo -j ACCEPT # 3. 允许已建立的和相关连接通过（关键！否则无法收到响应包） iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT # 4. 允许ICMP（ping命令） iptables -A INPUT -p icmp -j ACCEPT # 5. 开放特定服务端口（按需添加） iptables -A INPUT -p tcp --dport 22 -j ACCEPT # SSH iptables -A INPUT -p tcp --dport 80 -j ACCEPT # HTTP iptables -A INPUT -p tcp --dport 443 -j ACCEPT # HTTPS # 进入防火墙的数据包目的地址转换，从网口 eth0 进入的数据包，把目的 IP 为 114.115.116.117，端口为 80 的数据包，转到 10.0.0.1 # 这里外网用户访问公网地址 114.115.116.117:80，防火墙再转发到内网地址 iptables -t nat -A PREROUTING -i eth0 -d 114.115.116.117 -p tcp --dport 80 -j DNAT --to-destination 10.0.0.1 # 源地址转换，源地址 10.0.0.0/24 ，从网口 eth1 发出，并把源地址伪装成 111.112.113.114，响应回来后再转换为源地址 # 这里是内网地址 10.0.0.0/24 主机访问外网，会将内网地址伪装成公网 IP 111.112.113.114 iptables -t nat -A POSTROUTING -s 10.0.0.0/24 -i eth1 -j SNAT --to-source 111.112.113.114 规则的顺序问题：\n规则的顺序很重要，先匹配的规则先执行。 如果没有匹配的规则，那么就会使用默认策略。 # 可以接收从 IP 为 10.0.0.1 发送的数据包 iptables -t filter -A INPUT -s 10.0.0.1 -j ACCEPT iptables -A INPUT -s 10.0.0.2 -j ACCEPT iptables -A INPUT -s 10.0.0.2 -j DROP INPUT 链配置了两条规则：\n分别是接收 IP 为 10.0.0.2 的数据包； 和丢弃 IP 为 10.0.0.2 的数据包。 那么 10.0.0.2 的数据包能不能进来？\n可以。数据包会先匹配前面的 ACCEPT 10.0.0.2 的规则，这个时候数据包就进入了系统，所以规则顺序很重要。可以使用 -I 把规则从头插入：\niptables -I INPUT -s 10.0.0.2 -j ACCEPT","命令#命令":"命令格式：iptables [-t 表] 命令选项 [规则链] 规则\n-t 选项默认使用的是 filter 表。","命令选项#命令选项":"-A (Append)\t在链的末尾追加一条新规则。 例如：iptables -A INPUT -s 192.168.1.100 -j DROP 表示在 INPUT 链的末尾追加一条规则，当源 IP 是 192.168.1.100 时，拒绝该数据包。 -I (Insert)\t在链的指定位置插入一条新规则（默认为第1条）。 例如：iptables -I INPUT 3 -p tcp --dport 80 -j ACCEPT 表示在 INPUT 链的第 3 条位置插入一条规则，当协议是 TCP 且目标端口是 80 时，接受该数据包。 -D (Delete)\t从链中删除一条规则。 例如：iptables -D INPUT -s 192.168.1.100 -j DROP 表示从 INPUT 链中删除一条规则，当源 IP 是 192.168.1.100 时，拒绝该数据包。 -F (Flush) 清空指定链（或所有链）的所有规则。 例如：iptables -F INPUT 表示清空 INPUT 链的所有规则。 -L (List) 列出指定链（或所有链）的所有规则。 例如：iptables -L -n -v 表示列出所有链的所有规则，且不显示 IP 地址和端口号，而是显示数字形式的 IP 地址和端口号。 -N (New) 创建一条新的用户自定义链。 例如：iptables -N CUSTOM_CHAIN 表示创建一条名为 CUSTOM_CHAIN 的用户自定义链。 -X (Delete chain) 删除一条用户自定义链。 例如：iptables -X CUSTOM_CHAIN 表示删除名为 CUSTOM_CHAIN 的用户自定义链。 -P (Policy)\t设置链的默认策略（所有规则都不匹配时执行的动作）。 例如：iptables -P INPUT DROP 表示设置 INPUT 链的默认策略为 DROP，即所有不匹配的数据包都被拒绝。","小结#小结":"表和链的关系：你可以想象数据包流经一条“链”时，会依次经过挂在这条链上的不同“表”的规则检查。\n表的优先级顺序决定了检查的先后次序：raw -\u003e mangle -\u003e nat -\u003e filter。","工作流程数据包的一生#工作流程：数据包的一生":"入口 (PREROUTING)： 数据包从网卡进入系统。 首先经过 PREROUTING 链。这里会依次应用 raw、mangle、nat 表中的规则。 关键：在 nat 表的 PREROUTING 链中，可以做 DNAT（目标地址转换），比如把访问公网IP 80 端口的数据包转发到内网服务器的 192.168.1.10:80。 路由判断 (Routing Decision)： 内核查看数据包的目标 IP 地址，决定这个包是发给本机的（走 INPUT 链）还是需要转发的（走 FORWARD 链）。 发给本机 (INPUT)： 数据包进入 INPUT 链。这里会依次应用 mangle 和 filter 表中的规则。 关键：在 filter 表的 INPUT 链中，设置防火墙规则的主要地方。比如只允许特定 IP 访问本机的 SSH 端口。 本机进程处理： 数据包被本机的用户进程（如 web 服务器、SSH 服务）接收和处理。 本机发出 (OUTPUT)： 本机进程产生新的数据包，准备发送出去。 数据包进入 OUTPUT 链。这里会依次应用 raw、mangle、nat、filter 表中的规则。 关键：在 filter 表的 OUTPUT 链中，可以控制本机能发出哪些数据包。 转发 (FORWARD)： 如果数据包是转发的（第2步判断），则进入 FORWARD 链。 这里会依次应用 mangle 和 filter 表中的规则。 关键：在 filter 表的 FORWARD 链中，设置转发规则的主要地方。比如允许内网网段访问互联网，但禁止两个内网网段之间互访。 出口 (POSTROUTING)： 所有即将从网卡发出的数据包（无论是本机产生的还是转发的），最后都要经过 POSTROUTING 链。 这里会依次应用 mangle 和 nat 表中的规则。 关键：在 nat 表的 POSTROUTING 链中，可以做 SNAT（源地址转换），也就是常说的“IP伪装”（Masquerading），让内网机器共享一个公网IP上网。 离开：数据包离开网卡，前往下一个目的地。","核心思想#核心思想":"","表#表":"系统预定义了五个表，但最常用的是前两个：\nfilter 表：负责过滤数据包，决定是否放行。这是最常用的表。 内置链：INPUT, FORWARD, OUTPUT。 nat 表：负责网络地址转换（NAT）。 内置链：PREROUTING (DNAT), OUTPUT, POSTROUTING (SNAT)。 mangle 表：负责修改数据包的头信息（如 TTL、TOS）。 内置链：所有五个链 (PREROUTING, INPUT, FORWARD, OUTPUT, POSTROUTING)。 raw 表：负责连接跟踪机制的处理（如决定是否对数据包进行状态跟踪）。 内置链：PREROUTING, OUTPUT。 security 表（较少用）：用于强制访问控制（MAC）网络规则。","规则匹配与动作target#规则匹配与动作（Target）":"每条规则都由两部分组成：匹配条件（Matches） 和 动作（Target）。\n匹配条件：例如 -p tcp --dport 22（协议是 TCP 且目标端口是 22）、-s 192.168.1.100（源 IP 是 192.168.1.100）。 动作（Target）：当数据包匹配规则后要执行的操作。常见的有： ACCEPT：接受数据包，允许其通过。 DROP：丢弃数据包，没有任何响应。就像对方从来没发过这个包一样。更安全。 REJECT：拒绝数据包，并向发送方返回一个 connection refused 的错误消息。更友好。 SNAT：在 nat 表中使用，修改源地址。 DNAT：在 nat 表中使用，修改目标地址。 MASQUERADE：是 SNAT 的一种特殊形式，适用于动态获取 IP 的场合（如拨号上网）。 LOG：将匹配的数据包信息记录到系统日志（/var/log/messages 等），然后继续匹配后续规则。用于调试。","规则选项#规则选项":"-i 输入网口 -o 输出网口 -p 匹配网络协议：tcp、udp、icmp --icmp-type type 匹配 ICMP 类型，和 -p icmp 配合使用。 -s 匹配来源主机（或网络）的IP地址 --sport port 匹配来源主机的端口，和 -s source-ip 配合使用。 -d 匹配目标主机的 IP 地址 --dport port 匹配目标主机（或网络）的端口，和 -d dest-ip 配合使用。 -j 动作：指定规则匹配后要执行的动作。 例如：-j ACCEPT 表示接受该数据包。 例如：-j DROP 表示拒绝该数据包。 例如：-j LOG 表示记录该数据包的信息到系统日志。 例如：-j SNAT --to-source 192.168.1.100 表示修改源地址为 192.168.1.100。 例如：-j DNAT --to-destination 192.168.1.100 表示修改目标地址为 192.168.1.100。 例如：-j CUSTOM_CHAIN 表示跳转到名为 CUSTOM_CHAIN 的用户自定义链。 例如：-j MASQUERADE 表示使用动态获取的 IP 地址进行 SNAT。","链#链":"链是规则的集合，这些规则按顺序排列。数据包到达某个链时，会从第一条规则开始依次匹配，一旦匹配成功，就执行该规则定义的动作（如放行、拒绝），并停止后续匹配。如果所有规则都不匹配，则执行该链的默认策略（Policy）。\n系统预定义了五个最重要的链（对应数据包流经的不同阶段）：：\nINPUT：处理本机接收的数据包（例如，有人 ping 你的机器或 SSH 连接到你的机器）。 OUTPUT：处理本机发出的数据包（例如，你从本机 ping 别人）。 FORWARD：处理经过本机路由的数据包（你的机器充当路由器或网关时）。 PREROUTING：(nat 表) 数据包刚到达防火墙，在进行路由判断之前（可用于修改目标地址，即 DNAT）。 POSTROUTING：(nat表) 数据包即将离开防火墙，在进行路由判断之后（可用于修改源地址，即 SNAT）。"},"title":"iptables"},"/devops-learn/docs/linux/firewall/02_firewalld/":{"data":{"":"firewalld 的使用比 iptables 简单，主要区别：\nfirewalld 使用区域和服务而不是链式规则。 它动态管理规则集，允许更新规则而不破坏现有会话和连接。 使用：\nsystemctl start|stop|enable|disbale firewalld.service 控制 firewalld 服务。 firewqll-cmd 是 firewalld 配置命令。 iptables 和 firewalld 同时运行会产生冲突，应该关闭其中一个。\n# 查看状态 [root@shcCentOS72VM07 ~]# firewall-cmd --state # 重新加载配置 [root@shcCentOS72VM07 ~]# firewall-cmd --reload # 查看具体信息 [root@shcCentOS72VM07 ~]# firewall-cmd --list-all public (active) # public 就是一个区域 zone target: default icmp-block-inversion: no interfaces: eth0 sources: 10.0.0.1 10.0.0.1/24 services: ssh dhcpv6-client ports: 80/tcp 23/tcp protocols: masquerade: no forward-ports: sources-ports: icmp-blocks: rich rules: # 上面的输出表示 public zone 绑定了 eth0 网口， # source IP 为 10.0.0.1 10.0.0.1/24 的请求可以访问 80 端口和 23端口，还可以访问 ssh 服务和 dhcpv6-client 服务。 [root@shcCentOS72VM07 ~]#"},"title":"firewalld"},"/devops-learn/docs/sre/":{"data":{"":"","sre-是什么#SRE 是什么":"CN 40 ali shanghai CN 20 Azure CN north3"},"title":"SRE 实践"},"/devops-learn/docs/terraform/":{"data":{"":"","什么是-iac#什么是 IaC":"IaC 是 Infrastructure as Code 的缩写，即基础设施即代码。\n基础设施及代码是一种方法，通过代码来定义和管理基础设施，而不是通过手动操作来完成。\nIaC 工具：\nAzure：ARM Template 和 Bicep； GCP：Google Cloud Deployment Manager； AWS：CloudFormation； 全平台：Terraform。 这些 IaC 工具采用了完全声明式模型。用户不再关注过程步骤，而是在配置文件中定义了他们期望的基础设施状态。\n这些工具将这种状态与现实进行协调，自动执行实现结果所需的行动。Terraform 引入了状态文件来跟踪资源，从而实现增量更新和可扩展性，而 CloudFormation 利用 JSON 或 YAML 模板以声明方式管理 AWS 资源。两者都为命令式模型带来的挑战提供了独特的解决方案。","声明式和命令式#声明式和命令式":"基础设施即代码（IaC）的演进，历经了从命令式到声明式的重大转变。\n在早期的命令式配置管理阶段，Chef和Puppet等工具的崛起，标志着基础设施配置自动化的新篇章。这些平台通过明确地概述实现所需配置的步骤，为用户提供了一种全新的配置系统方法。然而，随着业务需求的不断变化和技术的飞速发展，单纯的命令式管理已难以满足日益复杂的环境需求。\n声明式 IaC 应运而生。它打破了传统的命令式束缚。让用户能够更专注于描述目标状态，而非具体实现细节。\n声明式的优点：\n幂等性：无论执行多少次，都能得到相同的结果。不会导致多次创建或者破坏其他资源。 简单，减少出错：用户不必知道当前设置的状态，不需要指定如何从当前状态转变到目标状态。只需要定义所期望的状态，Terraform 会自动计算出当前状态与期望状态的差异，并执行必要的操作。 文档化：配置文件本身就是基础设施的最新、最准确的文档。 版本控制与可追溯性：基础设施代码可以像应用代码一样进行版本管理（Git），方便审查、回滚和审计。"},"title":"Terraform"},"/devops-learn/docs/terraform/01_terraform/":{"data":{"":"","aws#AWS":"静态凭证 (Static Credentials) - 不推荐用于生产 硬编码 (极不推荐，最不安全)，会被提交到 Git 仓库：\nprovider \"aws\" { region = \"us-west-2\" access_key = \"my-access-key\" secret_key = \"my-secret-key\" } 环境变量：\nexport AWS_ACCESS_KEY_ID=\"anaccesskey\" export AWS_SECRET_ACCESS_KEY=\"asecretkey\" export AWS_REGION=\"us-west-2\" terraform plan provider \"aws\" {} 共享凭证文件：\nexport 环境变量的方式只在当前 Terminal 生效，关闭 Terminal 后就失效了。想要全局生效，使用凭证文件 ~/.aws/credentials。\nprovider \"aws\" { region = \"us-west-2\" } 凭证文件：\n当你运行 aws configure 后，凭证会保存在 ~/.aws/credentials 中。Terraform 会自动读取这个文件。\n# ~/.aws/credentials [default] aws_access_key_id = AKIAIOSFODNN7EXAMPLE aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY 对应的 ~/.aws/config 文件定义区域：\n# ~/.aws/config [default] region = us-east-1 避免使用静态凭证，尤其是硬编码。如果必须使用，请仅用于个人测试账户，并确保 terraform 文件绝不包含凭证并提交到 Git。\nIAM 角色和临时安全凭证 (IAM Roles \u0026 Temporary Security Credentials) 这是 AWS 和 Terraform 推荐的最佳实践，因为它提供了更高的安全性。凭证是临时的（默认最多 1 小时），过期后自动失效，无需轮换。\n通过环境变量提供临时凭证：\n临时凭证除了 Access Key 和 Secret Key，还有一个 Session Token。\nexport AWS_ACCESS_KEY_ID=\"ASIAIOSFODNN7EXAMPLE\" export AWS_SECRET_ACCESS_KEY=\"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\" export AWS_SESSION_TOKEN=\"your-very-long-session-token\" terraform plan 在共享凭证文件中配置临时凭证：\n在 ~/.aws/credentials 中，可以为一个 Profile 配置临时凭证：\n[default] aws_access_key_id = ASIAIOSFODNN7EXAMPLE aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY aws_session_token = your-very-long-session-token IAM 实例配置文件 当 Terraform 运行在 AWS 资源内部时（例如在 EC2 实例上），这是最安全、最推荐的方式。\n原理：\n你创建一个 IAM 角色（Role）并授予它必要的权限。 你将这个角色附加（Attach）到 EC2 实例上（通过实例配置文件 Instance Profile）。 EC2 实例上的应用程序（包括 Terraform）可以通过内网的实例元数据服务 (IMDS) 自动获取该角色的临时安全凭证。 Terraform AWS Provider 会自动发现并使用这些凭证，你无需做任何配置。","backend#backend":"backend 是 Terraform 用来存储状态文件的地方。","data-sources-示例#Data Sources 示例":"Provider 的文档中，不仅有 Resource，还有 Data Source。例如 EC2 目录下有 Resources，还有 Data Sources。\ndata \"aws_vpc\" \"exist_vpc\" { # 这里可以定义的过滤条件，告诉 aws，按照什么条件去查找，输出一个符合条件的 VPC # filter {} default = true # 表示如果没有找到符合条件的 VPC，就使用默认的 VPC } resource \"aws_subnet\" \"dev_subnet\" { vpc_id = data.aws_vpc.exist_vpc.id cidr_block = \"10.0.1.0/24\" # 不能和默认的 VPC 下的子网的 CIDR 冲突 availability_zone = \"us-east-1a\" }","for-循环示例#For 循环示例":"resource \"azurerm_resource_group\" \"resourcegroup\" { name = var.resource_group_name location = var.location # 引用变量，使用 var.\u003c变量名\u003e } resource \"azurerm_virtual_network\" \"vnet\" { name = \"ExampleVNet\" address_space = [\"10.0.0.0/16\"] location = azurerm_resource_group.resourcegroup.location resource_group_name = azurerm_resource_group.resourcegroup.name # 不使用 var.resource_group_name，因为创建顺序是无序的， # 直接使用，可能会报错，因为 vnet 依赖 resource group，而 resource group 没有创建完成，var.resource_group_name 这个 resource group 还不存在 } resource \"azurerm_subnet\" \"subnet\" { for_each = var.subnets # for each 变量 subnets，遍历里面每一个 instance resource_group_name = azurerm_resource_group.resourcegroup.name virtual_network_name = azurerm_virtual_network.vnet.name name = each.value[\"name\"] # 提取变量 subnets 中的一个元素的 name 的值 address_prefixes = each.value[\"address_prefixes\"] # 提取变量 subnets 中的一个元素的 address_prefixes 的值 } variables.tf：\nvariable \"subnets\" { type = map(any) default = { subnet_1 = { name = \"Subnet1\" address_prefixes = [\"10.0.0.0/24\"] # []代表列表，一个或多个值 } subnet_2 = { name = \"Subnet2\" address_prefixes = [\"10.0.1.0/24\"] } subnet_3 = { name = \"Subnet3\" address_prefixes = [\"10.0.2.0/24\"] } bastion_subnet = { name = \"AzureBastionSubnet\" # bastion 的 subnet 必须是这个名字 address_prefixes = [\"10.0.250.0/24\"] } } }","module-示例#Module 示例":"模块用来存储可复用的代码，如果在每一个 terraform 项目中都写一遍相同的代码，会导致代码重复。这个时候就可以使用模块，\nModule 是有层级的，例如：\nterraformpro ├── main.tf ├── variables.tf ├── outputs.tf ├── terraform.tfvars ├── modules │ ├── module1 │ │ ├── main.tf │ │ ├── variables.tf │ │ ├── outputs.tf │ │ ├── terraform.tfvars │ ├── module2 │ ├── module3 main.tf：\n# call module1 which has 2 variables module \"module1\" { source = \"./modules/module1\" # 指定模块的路径 basename = \"examplemodule1\" # 设置模块变量的值 location = \"West Europe\" # 设置模块变量的值 } # call module2 which has 3 variables module \"module2\" { source = \"./modules/module2\" basename = \"examplemodule2\" # resource_group_name 是 module1 创建完以后返回的，虽然我们可以知道 module1 创建的 resource group 名称是 ExampleRG # 但是在 module2 中并不想写死 # module1 的 output 文件输出了 resource_group_name resource_group_name = module.module1.resource_group_name location = \"West Europe\" } module1/outputs.tf：\n# 模块输出 resource_group_name output \"resource_group_name\" { # \u003c资源类型\u003e.\u003c资源名称\u003e. value = azurerm_resource_group.resourcegroup.name } 一个 output 属性只能定义一个 value。","state-命令#state 命令":"terraform state 命令用于查看和管理 Terraform 状态文件。\nterraform state list：列出状态文件中的所有资源。 terraform state show ：显示指定资源的详细信息。这在调试、查找特定信息（如 IP 地址、ARN）时极其有用。 terraform state rm ：从状态文件中删除指定资源。但不会销毁实际的云资源。 如果有人绕过 Terraform 在控制台上删除了资源，状态文件中就会留下一个“幽灵”记录。terraform plan 会报错说资源找不到。这时可以用 state rm 来清理这个无效记录。 terraform state rm aws_instance.web Terraform 会“忘记”它曾管理过这个 EC2 实例，但该实例仍在 AWS 中运行。下次 apply 时，Terraform 会试图创建一个新的 aws_instance.web（如果配置还在），导致资源冲突。 terraform state pull：从远程后端拉取最新状态。terraform state pull \u003e state.json 主要用于编程式处理状态文件内容，或者用于调试复杂问题。 terraform state push：将本地状态推送到远程后端。 terraform state mv ：移动资源在状态文件中的位置。不会影响真实的基础设施。云上的资源完好无损，只是 Terraform 管理它的“名字”变了。你必须提前在代码中配置好目标资源块。这个命令只修改状态，不修改代码。","terraformtfstate-什么时候更新#terraform.tfstate 什么时候更新":"成功执行 terraform apply 或 terraform destroy 命令后更新。","terraformtfstatebackup#terraform.tfstate.backup":"terraform.tfstate.backup 是一个备份文件，是 Terraform 在覆盖当前状态文件 (terraform.tfstate) 之前自动创建的备份副本。它的核心作用是充当“后悔药”，让你在操作失败或出现意外时，能够恢复到操作前的已知状态。\nterraform.tfstate.backup 会在你执行任何会修改状态文件的 Terraform 命令时生成。具体来说，当以下两个条件同时满足时：\n执行了会修改状态文件的操作： terraform apply（创建、更新或销毁资源） terraform destroy terraform refresh （替代品 apply -refresh-only 也会） 使用 -target 参数的上述命令 terraform import 使用本地后端 (local backend)：即你的状态文件 (terraform.tfstate) 存储在本地磁盘上。如果你使用了远程后端（如 S3、Azure Storage），Terraform 通常不会在本地生成 .backup 文件，因为备份和版本控制由后端自己处理（例如 S3 的对象版本控制）。","variable-示例#Variable 示例":"variables.tf：\nvariable \"location\" { type = string default = \"West Europe\" description = \"The location of the resource group.\" } variable \"storage_account_name\" { type = string description = \"The name of the storage account.\" # 没有默认值，因为每个 storage account 名称在 azure 中是全局唯一的。 } main.tf：\n# locals 也是一个变量，本地变量 # 本地变量可存储重复出现的值或表达式，例如多次引用的配置信息。通过 locals 块声明后，可避免在多个地方重复编写相同内容 # locals 的作用域是模块级别的 # - 目录作用域：在同一个 Terraform 模块目录（包含所有 .tf 文件的那个目录）中，任何地方定义的 locals 块在整个模块中都可用 # - 全局可见：一旦在某个 locals 块中定义了一个值（例如 local.name_prefix），你可以在同一个模块的任何 .tf 文件中通过 local.name_prefix 引用它 # - 不可跨模块：locals 对于父模块或子模块是不可见的。如果需要在模块间共享值，应该使用 output。 # 引用 locals 变量时，直接使用 local.\u003c变量名\u003e locals { tags = { usage = \"test\" owner = \"sid\" } } resource \"azurerm_resource_group\" \"resourcegroup\" { # name = \"${var.prefix}-RG\" 这是另一种变量的用法，可以将 var.prefix 和 -RG 组成一个字符串 name = \"ExampleRG\" location = var.location # 引用变量，使用 var.\u003c变量名\u003e } resource \"azurerm_storage_account\" \"storageaccount\" { name = var.storage_account_name resource_group_name = azurerm_resource_group.resourcegroup.name # 引用资源，使用 \u003c资源类型\u003e.\u003c资源名称\u003e. location = azurerm_resource_group.resourcegroup.location # 这种方式表示在 resourcegroup 创建完了以后使用 resourcegroup 的 name/location account_tier = \"Standard\" account_replication_type = \"LRS\" tags = local.tags } storage_account_name 没有默认值，所以肯定需要指定一个值。有两种方式：\n在 terraform apply 时，会提示输入 storage_account_name 的值。 在 terraform plan/apply 时，需要添加 -var \"storage_account_name=mystorageaccount\" 来指定这个值。不方便。 创建 terraform.tfvars 文件，在文件中指定变量的值。最推荐的方式。 环境变量 terraform.tfvars 文件：\nstorage_account_name = \"mystorageaccount\"","variable-类型#Variable 类型":"string number bool list()：列表，例如 list(string) set()：集合，例如 set(string) map()：映射对象，例如 map(string) object({ = , ... })：对象，例如 object({ name = string, age = number }) tuple([, ...])：元组，例如 tuple([string, number, bool]) variable \"image_id\" { type = string } variable \"availability_zone_names\" { type = list(string) default = [\"us-west-1a\"] } variable \"docker_ports\" { type = list(object({ internal = number external = number protocol = string })) default = [ { internal = 8300 external = 8300 protocol = \"tcp\" } ] }","workspace#workspace":"Workspaces 隔离的是 State，而不是代码或变量。快速、轻量地创建配置相同但状态隔离的环境。\n它非常适用于短期存在的环境，如功能分支开发环境、临时测试环境，或者需要快速复制一套完整基础设施的场景。","什么时候应该避免使用-workspaces#什么时候应该避免使用 Workspaces？":"对于严格隔离的生产环境（Production），最佳实践通常不是使用 Workspaces，而是使用以下更强大的隔离方式：\n独立的 Terraform 配置目录：为 prod 和 dev 创建完全独立的代码目录。这提供了最强的隔离性。\n不同的版本控制分支：main 分支代表生产状态，dev 分支用于开发。\n不同的云账户（AWS Account / Azure Subscription）：这是黄金标准。通过物理账户边界实现绝对的权限和资源隔离。使用 Terraform 云提供商别名或不同的后端来管理不同账户的资源。\n不同的 Terraform 后端：为每个环境使用完全独立的 S3 桶和 DynamoDB 表来存储状态。","使用场景#使用场景":"你有一套定义好的基础设施代码（例如：1个VPC、2个EC2实例、1个RDS数据库）。现在你需要为功能开发、测试和预发布各部署一套完全一样但完全隔离的环境。\n# 创建新工作区 terraform workspace new feature-login terraform workspace new staging terraform workspace new preprod # 切换工作区并部署 terraform workspace select feature-login terraform apply -var-file=feature.tfvars terraform workspace select staging terraform apply -var-file=staging.tfvars terraform workspace select preprod terraform apply -var-file=preprod.tfvars","使用已经存在的-module#使用已经存在的 module":"module \"vpc\" { source = \"terraform-aws-modules/vpc/aws\" name = \"my-vpc\" cidr = \"10.0.0.0/16\" azs = [\"eu-west-1a\", \"eu-west-1b\", \"eu-west-1c\"] private_subnets = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"] public_subnets = [\"10.0.101.0/24\", \"10.0.102.0/24\", \"10.0.103.0/24\"] enable_nat_gateway = true enable_vpn_gateway = true tags = { Terraform = \"true\" Environment = \"dev\" } }","修复一个被手动修改的资源#修复一个被手动修改的资源":"发现问题：terraform plan 报告说有漂移（drift），比如安全组的规则被人在 AWS 控制台上改了。 先使用 terraform state show 查看资源的当前状态。 查看真实状态：去 AWS 控制台确认安全组的真实规则。 修复 drift：根据 AWS 控制台的真实规则，修改 Terraform 配置文件。 执行 terraform apply 应用变更。 确认资源已被正确创建或更新。","其他常用命令#其他常用命令":"","参数#参数":"HCL 中的参数就是将一个值赋给一个特定的名称：\nname = \"example\" 等号前的标识符就是参数名，等号后的表达式就是参数值。","基本工作流程#基本工作流程":"Init 初始化，初始化工作目录。下载配置中声明的 Provider 插件、模块等依赖项。 terraform init，第一次使用新配置时，或添加/修改了 Provider 或模块后。 Plan 计划，它会对比状态文件（当前状态）和配置文件（期望状态），然后生成一个执行计划，算出来需要执行的步骤。 terraform plan 在真正应用变更之前进行审查和确认，避免意外操作。 Apply 应用，会根据执行计划，来执行你的操作。 terraform apply，执行计划中的变更，使现实基础设施的状态与你的配置保持一致。 你可以在 apply 时添加 -auto-approve 参数，来自动 approve 这个计划。否则会提示你是否 approve 这个计划。 你也可以在 apply 时添加 -target 参数，来指定只执行某个资源。 你也可以在 apply 时添加 -destroy 参数，来指定只删除某个资源。 Destroy 销毁，会销毁所有资源。也需要确认是否销毁。支持 -auto-approve。 terraform destroy，清理环境，避免产生不必要的费用。 删除资源可以直接在配置文件中删除配置，然后执行 terraform apply 来删除资源（推荐）。 也可以使用 terraform destroy -target \u003c资源类型\u003e.\u003c资源名称\u003e 来删除指定资源，不推荐，因为会导致状态与配置文件不一致。所有的更改都应该通过配置文件来进行。","多个环境#多个环境":"对于多个环境，每个环境的变量值可能会不同。\n例如：\n开发环境 测试环境 生产环境 每个环境的变量值可能会不同，每个环境都创建一个 terraform.tfvars 文件。例如：\n开发环境：terraform-dev.tfvars 测试环境：terraform-test.tfvars 生产环境：terraform-prod.tfvars apply 时，需要添加 -var-file 来指定 terraform.tfvars 文件的路径。例如：\nterraform apply -var-file=terraform.dev.tfvars","失败#失败":"apply 失败会生成 crash.log 文件, 可以根据这个文件来调试.","如何在工作区之间实现差异配置#如何在工作区之间实现差异配置？":"使用输入变量和条件表达式。\n使用不同的变量文件（.tfvars）（推荐）：\nterraform workspace select dev terraform apply -var-file=\"dev.tfvars\" terraform workspace select prod terraform apply -var-file=\"prod.tfvars\"","它有什么用#它有什么用？":"这是一个灾难恢复机制。\n操作失败或中断： apply 操作在执行中途失败（如网络中断、权限突然失效、配额不足）。 此时，部分资源可能已经被创建或修改，而另一部分没有。 结果：状态文件 (terraform.tfstate) 可能处于一个不完整、不一致或损坏的状态，因为它只记录了一部分变更。 意外后果： apply 操作成功完成了，但引入了一个你未曾预料到的严重问题（例如，错误地覆盖了一个关键配置）。 结果：状态文件是最新的，但基础设施的状态是错误的。 在这些情况下，可以检查 .backup 文件，了解操作开始前基础设施的状态。从而进行问题诊断。","标识符#标识符":"合法的标识符可以包含字母、数字、下划线(_)以及连字符(-)。 标识符首字母不可以为数字。","核心配置块#核心配置块":"terraform 配置块：定义 Terraform 版本、插件源等。 required_providers：指定所需的 Provider 插件源及其版本。 backend：配置状态文件的存储后端，如本地文件、远程后端（如 S3 + DynamoDB）等。 provider 配置块 定义使用的 Provider 插件，如 AWS、Azure、GCP 等。 配置 Provider 插件的认证信息，如 API 密钥、访问令牌等。 resource 配置块 定义要创建的资源，如 AWS 实例、GCP 存储桶等。 配置资源的属性，如实例类型、存储桶名称等。 variable 配置块 定义输入变量，如输入参数、环境变量等。 配置变量的默认值，如 default = \"us-east-1\"。 output 配置块 定义输出值，应用完成后公开一些有用的信息（如服务器的 IP 地址）。 配置输出值的描述，如 description = \"The ID of the created instance\"。 配置输出值的敏感信息，如 sensitive = true，可以防止输出值被打印到日志中。 data 配置块 定义数据源，用于从提供商获取外部数据或查询已有资源的信息，以便在配置中使用。 配置数据源的属性，如实例 ID、存储桶名称等。 module 配置块 调用模块，将多个资源封装成一个可重用的单元。 配置模块的参数，对于 module 来说,输入变量就像函数的参数,输出值就像函数的返回值. output 用来导出资源的属性到父级模块 只有将一组资源组合在一起的 module 才有意义, 例如一组网络资源, 一组数据库资源等. 可以创建自己的模块,也可以使用其他存在的模块,例如 terraform 官方提供的模块 terraform-aws-modules/vpc locals 配置块 定义本地变量，用于在配置中重复使用的值。 配置本地变量的表达式，如 local_var = \"value\"。","概念#概念":"Providers (提供商) 是什么：Provider 是 Terraform 的插件，用于与特定的云平台（如 AWS, Azure, GCP）、 SaaS 服务（如 Cloudflare, Datadog）或本地基础设施（如 vSphere, Docker）进行交互。 作用：Provider 负责理解 API 交互并将资源创建、更新和删除的请求翻译成具体的 API 调用。 如何使用：在配置中通过 provider 块进行声明和配置（例如，设置 region 和 access key）。 示例：aws, azurerm, google, kubernetes, null。 Resources (资源) 是什么：Resource 是 Terraform 配置中最重要的元素，代表一个具体的基础设施资源。 作用：定义一个需要被创建、管理和销毁的资源实体，例如一台虚拟机、一个网络安全组、一个 S3 存储桶。 结构：resource \"resource_type\" \"resource_name\" { ... } resource_type：由 Provider 提供（如 aws_instance）。 resource_name：你在当前 Terraform 模块内给这个资源起的逻辑名称（标识符）。 示例：resource \"aws_instance\" \"my_web_server\" { ami = \"ami-12345\", instance_type = \"t2.micro\" } Input Variables (输入变量) 是什么：类似于函数的参数，用于从外部向 Terraform 模块传递值。 作用：参数化配置，提高代码的灵活性和可复用性。避免将敏感信息或环境特定的值硬编码在配置文件中。 如何定义：在 variables.tf 文件中使用 variable 块声明。 如何赋值：可以通过命令行 -var \"var_name=var_value\" 选项、.tfvars 文件、环境变量等方式传入。 Output Values (输出值) 是什么：类似于函数的返回值，用于将模块内部资源的信息暴露给外部。 作用：共享资源的属性（例如，新创建服务器的公有 IP 地址），以便其他 Terraform 配置或外部世界可以使用。 如何定义：在 outputs.tf 文件中使用 output 块声明。 State (状态) 是什么：一个名为 terraform.tfstate 的 JSON 文件，它极其重要。它存储了 Terraform 所管理基础设施的当前状态和属性映射。 作用： 映射现实：将你的配置文件（.tf）中的资源定义映射到现实世界中的真实资源 ID。 元数据存储：存储资源的依赖关系、属性等信息，用于计算增量变更。 性能：缓存资源信息，避免每次执行都需查询所有云资源。 重要提示：必须安全地存储和备份状态文件（例如使用远程后端如 S3 + DynamoDB），严禁手动修改。团队成员间应共享同一份状态文件以避免配置冲突。 Modules (模块) 是什么：将多个资源组合成一个更大、可重用单元的容器。一个模块就是一个包含 Terraform 配置文件（main.tf, variables.tf, outputs.tf）的目录。 作用：抽象和封装基础设施，实现代码复用和组织化。你可以创建自己的模块，也可以使用来自 Terraform Registry 的公共模块。 根模块：执行 terraform apply 时所在的目录。 子模块：在配置中通过 module 块调用的其他模块。 Data Sources (数据源) 是什么：数据源允许 Terraform 从外部数据源获取信息，而不是从本地配置文件中获取。比如现在要在一个现有的 aws VPC 中创建一个子网，而不是新的 VPC，如何获取 VPC id。Resource 用于创建和管理基础设施资源，Data Source 用于检索和利用现有基础设施资源的信息。 可以从控制台获取 VPC id，比较麻烦。 可以从数据源中获取 VPC id。 作用：检索和利用现有基础设施资源的信息，在配置中引用。 如何定义：在 data.tf 文件中使用 data 块声明。 示例：data \"aws_ami\" \"example\" { most_recent = true, owners = [\"self\"] } Resource 与 Data Source 可以看作为函数，Resource 的定义是一个创建资源的函数，然后传递参数给 Terraform，来创建对应的实体。Data Source 可以看作是一个查找并返回现有实体信息的函数，可以指定查询的条件和参数。","注释#注释":"# Configuration options 单行注释 // Configuration options 单行注释 /* 多行注释 Configuration options Configuration options */","状态#状态":"terraform 会将资源的状态保存在状态文件中。默认是 terraform.tfstate。这是一个 JSON 文件。\n每当更新资源后，terraform 会更新状态文件。\n如果删除了所有资源，那么 resources 会是一个空数组。","环境变量#环境变量":"可以通过设置名为 TF_VAR_ 的环境变量为输入变量赋值，例如：\n$ export TF_VAR_image_id=ami-abc123 $ terraform plan Terraform 要求环境变量中的 与 Terraform 代码中定义的输入变量名大小写完全一致。\nvariable \"image_id\" { type = string } 环境变量传值非常适合在自动化流水线中使用，尤其适合用来传递敏感数据，类似密码、访问密钥等。","示例#示例":"","简单示例#简单示例":"main.tf：\nterraform { required_providers { azurerm = { source = \"hashicorp/azurerm\" version = \"4.41.0\" } } } provider \"azurerm\" { # Configuration options # features 是必须的，可以为空 features {} } resource \"azurerm_resource_group\" \"example\" { name = \"ExampleRG\" location = \"West Europe\" } 运行 terraform init 初始化。会去搜索对应版本的 provider 插件下载，并安装到 .terraform 目录下。这个目录下会有一个可执行文件，就是 provider。\n.terraform.lock.hcl 是用来记录 provider 插件的版本信息的。包括 hash 值。\n如果已经运行了 az 登录，那么执行 terraform plan：\nterraform plan # 输出 Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # azurerm_resource_group.example will be created + resource \"azurerm_resource_group\" \"example\" { + id = (known after apply) + location = \"West Europe\" + name = \"ExampleRG\" } Plan: 1 to add, 0 to change, 0 to destroy. 执行 terraform apply 来创建资源。\n输出：\nTerraform will perform the following actions: # azurerm_resource_group.example will be created + resource \"azurerm_resource_group\" \"example\" { + id = (known after apply) + location = \"West Europe\" + name = \"ExampleRG\" } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes Apply complete! Resources: 1 added, 0 changed, 0 destroyed. 执行完以后会同时创建一个 terraform.tfstate 文件，用来记录所有被 terraform 管理的资源的状态。\nterraform 会使用这个状态文件去和 main.tf 中定义的资源进行对比，来判断是否需要创建、更新、删除资源。来达到预期的状态。","语法#语法":"","身份认证#身份认证":"如何证明你有权限在对应的云平台上操作。Terraform 本身不处理认证，而是委托给下载的 Provider 插件，并由插件遵循对应云平台的认证标准。\n云平台 认证方式 (推荐顺序) Terraform Provider 如何获取凭证 AWS 1. IAM 角色 (用于 EC2/ECS 等) 2. 共享凭证文件 (~/.aws/credentials) 3. 环境变量 4. 硬编码 (极不推荐) Provider 会使用 AWS SDK，自动按照标准 AWS CLI 的认证流程查找凭证。 Azure 1. 环境变量 (ARM_CLIENT_ID, ARM_CLIENT_SECRET, ARM_TENANT_ID, ARM_SUBSCRIPTION_ID) 2. CLI 认证 (az login) Provider 使用 Azure SDK，支持环境变量或自动继承已登录的 Azure CLI 的认证上下文。 Google Cloud 1. 应用默认凭证 (ADC) - gcloud auth application-default login 2. 服务账户密钥文件 3. 环境变量 Provider 使用 Google Cloud SDK，自动查找应用默认凭证或环境变量指定的密钥文件。 Kubernetes 1. 环境变量 (KUBERNETES_SERVICE_HOST, KUBERNETES_SERVICE_PORT) 2. 配置文件 (~/.kube/config) Provider 使用 Kubernetes 客户端库，自动查找环境变量或配置文件指定的集群信息。","运维工作流#运维工作流":"","远程后端#远程后端":"当团队多个人在使用时，每个人都会在本地执行 Terraform 命令, 或者正在将 Terraform 集成到 Jenkins 中。存在多个创建状态的地方.\n如何共享状态?\n远程后端存储.\nTerraform 引入了远程状态存储机制，也就是 Backend。Backend 是一种抽象的远程存储接口，如同 Provider 一样，Backend 也支持多种不同的远程存储服务：\nlocal remote azurerm consul cos gcs http kubernetes oss pg s3 状态锁是指，当针对一个 tfstate 进行变更操作时，可以针对该状态文件添加一把全局锁，确保同一时间只能有一个变更被执行。\n不同的 Backend 对状态锁的支持不尽相同，实现状态锁的机制也不尽相同，例如 consul Backend就通过一个 .lock 节点来充当锁。s3 Backend 则需要用户传入一个 Dynamodb 表来存放锁信息，而 tfstate 文件被存储在 S3 存储桶里。\nterraform { required_version = \"1.13.0\" backend \"s3\" { bucket = \"myapp-terraform-state-bucket\" key = \"myapp/terraform.tfstate\" region = \"eu-west-1\" } required_providers { aws = { source = \"hashicorp/aws\" version = \"~\u003e 4.0\" } } } 需要先去 aws 创建一个 s3 的 bucket. 名字是 my-terraform-state-bucket 然后在 bucket 中创建一个文件夹. 文件夹的名称就是 myapp/terraform.tfstate.\nbucket settings for Block Public Access:\nBlock all public access Bucket Versioning: bucket 版本控制,每次文件更改都会生成一个版本,可以回滚.\nEnable Default encryption: 开启默认加密, 可以防止数据泄露.\nDisable Create. 之后就创建了一个空桶","配置文件#配置文件":"Provider 部分 表示 provider 部分，用来指定你要使用的 provider，比如 aws，azure，gcp 等。\nterraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"6.10.0\" } } } provider \"aws\" { # Configuration options } 对于多个 provider 的情况，可以单独抽出一个 providers.tf 文件。\nterraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"6.10.0\" } azurerm = { source = \"hashicorp/azurerm\" version = \"4.41.0\" } tencentcloud = { source = \"tencentcloudstack/tencentcloud\" version = \"1.123.0\" } } } Resource 部分 表示 resource 部分，用来指定你要创建的资源，比如 aws 中的 ec2，rds 等。\n# resource # \"aws_instance\" 表示资源类型 # \"example\" 表示资源名称，注意这个名字是你自己定义的，是 local 的，不是 aws 中的资源名称。 resource \"aws_instance\" \"example\" { name = \"example\" # aws 中的资源名称 ami = \"ami-0c55b159cbfafe1f0\" instance_type = \"t2.micro\" } Variable 文件 例如定义 resource 我们需要填一些参数，比如 ami，instance type 等。这些参数我们可以定义在 variable 文件中。在 variable 文件中定义的变量的值，然后在 resource 中引用，避免在 main.tf 中改来改去。\nOutput 文件 在有些情况在，只有当这个资源被创建出来之后，你才知道这个资源的一些信息，比如 id， ip 地址，dns 名称等。\n如果你想使用这些值，作为以下资源的输入参数，就可以使用 output 来导出。","重命名资源#重命名资源":"假设我们有一个简单的 EC2 实例资源：\n# main.tf (原始代码) resource \"aws_instance\" \"old_name\" { ami = \"ami-123456\" instance_type = \"t3.micro\" } 想把资源标识符从 old_name 改为 new_name。\n首先，修改代码。将 main.tf 中的资源块改名。resource \"aws_instance\" \"new_name\"。 执行 state mv 命令。告诉 Terraform 状态文件中原来的那个资源现在由新的名字来管理。 最后，验证。运行 terraform plan。输出应该显示 No changes. 这意味着基础设施不需要任何变更，只是状态文件的内部记录更新了。 如果直接改代码而不运行 state mv，Terraform 会计划销毁 aws_instance.old_name 并创建 aws_instance.new_name。","限制#限制":"它只备份前一个状态，对于完整的历史跟踪，要使用： 版本控制工具（如 Git），手动将 terraform.tfstate 和 .backup 文件提交到 Git，但这非常不推荐，因为状态文件包含敏感信息。 远程后端（如 S3、Azure Storage），最佳实践。每次状态更新都会在云端保存一个历史版本，你可以随时回滚到任何历史版本。 远程后端的行为不同：对于远程后端，本地不会生成 .backup，但后端本身提供了更强大的版本历史、状态锁定和恢复功能。应该优先使用远程后端。","限性和风险#限性和风险":"容易人为失误：很容易忘记切换工作区。你可能以为自己身在 dev，但实际上在 prod，一个 terraform destroy 就会导致灾难性后果。必须时刻使用 terraform workspace show 确认当前工作区。\n代码复杂性：在代码中嵌入大量 terraform.workspace 的逻辑会使配置变得复杂和难以理解，降低了代码的可读性和可维护性。"},"title":"Terraform"},"/devops-learn/docs/terraform/07_resource/":{"data":{"":"","元参数#元参数":""},"title":"Resource 资源"},"/devops-learn/docs/terraform/project/":{"data":{"":"如果 .tfvars 文件包含敏感数据，例如密码、访问密钥等，建议将其添加到 .gitignore 文件中，避免将敏感数据提交到 Git 仓库中。\n.terraform.lock.hcl 包含了版本信息，应该提交到仓库里。"},"title":"目录结构"},"/devops-learn/docs/terraform/provisioner/":{"data":{"":"某些基础设施对象需要在创建后执行特定的操作才能正式工作。\n像这样创建后执行的操作可以使用预置器(Provisioner)。预置器是由 Terraform 所提供的另一组插件，每种预置器可以在资源对象创建后执行不同类型的操作。","cloud-init#cloud-init":"不少公有云厂商的虚拟机都提供了 cloud-init 功能，可以让我们在虚拟机实例第一次启动时执行一段自定义的脚本来执行一些初始化操作。\n首先要指出的是，provisioner 的官方文档里明确指出，由于预置器内部的行为 Terraform 无法感知，无法将它执行的变更纳入到声明式的代码管理中，所以预置器应被作为最后的手段使用，那么也就是说，如果 cloud-init 能够满足我们的要求，那么我们应该优先使用 cloud-init。","user_data#user_data":"user_data 执行的命令, Terraform 无法感知. 如果命令失败,不得不访问服务器,再进行调试.","user_data-和-provisioner-区别#user_data 和 provisioner 区别":"user_data: 原理是在实例启动时,将 user_data 中的内容写入到实例的 /var/lib/cloud/instance/user-data.txt 文件中,并执行该文件中的内容.\nprovisioner: 原理是在实例启动后, Terraform 通过 SSH 连接到实例,并执行 provisioner 中的命令.","为什么不建议使用-provisioner#为什么不建议使用 provisioner":""},"title":"Provisioner"}}